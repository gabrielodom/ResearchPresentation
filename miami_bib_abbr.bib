
@misc{center_for_history_and_new_media_zotero_nodate,
	title = {Zotero {Quick} {Start} {Guide}},
	url = {http://zotero.org/support/quick_start_guide},
	author = {{Center for History and New Media}},
	annote = {Welcome to Zotero!View the Quick Start Guide to learn how to begin collecting, managing, citing, and sharing your research sources.Thanks for installing Zotero.}
}

@article{choi_nonlinear_2004,
	title = {Nonlinear dynamic process monitoring based on dynamic kernel {PCA}},
	volume = {59},
	issn = {0009-2509},
	doi = {10.1016/j.ces.2004.07.019},
	abstract = {Nonlinear dynamic process monitoring based on dynamic kernel principal component analysis (DKPCA) is proposed. The kernel functions used in kernel PCA (KPCA) are profitable for capturing nonlinear property of processes and the time-lagged data extension is suitable for describing dynamic characteristic of processes. DKPCA enables us to monitor an arbitrary process with severe nonlinearity and (or) dynamics. In this respect, it is a generalized concept of multivariate statistical monitoring approaches. A unified monitoring index combined T 2 with SPE is also suggested. The proposed monitoring method based on DKPCA is applied to a simulated nonlinear process and a wastewater treatment process. A comparison study of PCA, dynamic PCA, KPCA, and DKPCA is investigated in terms of type I error rate, type II error rate, and detection delay. The monitoring results confirm that the proposed methodology results in the best monitoring performance, i.e., low missing alarms and small detection delay, for all the faults.},
	number = {24},
	urldate = {2016-10-14},
	journal = {Chem. Eng. Sci.},
	author = {Choi, Sang Wook and Lee, In-Beum},
	month = dec,
	year = {2004},
	keywords = {Dynamic kernel principal component analysis, Fault detection, Monitoring statistic, Nonlinear dynamic process, Process monitoring, Wastewater treatment process},
	pages = {5897--5908},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\QWXHVEPC\\Choi and Lee - 2004 - Nonlinear dynamic process monitoring based on dyna.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\N4QG79QQ\\S0009250904004555.html:text/html}
}

@book{fukunaga_introduction_1990,
	address = {Boston},
	edition = {2nd Edition},
	title = {Introduction to {Statistical} {Pattern} {Recognition}},
	isbn = {978-0-12-269851-4},
	abstract = {This completely revised second edition presents an introduction to statistical pattern recognition.  Pattern recognition in general covers a wide range of problems: it is applied to engineering problems, such as character readers and wave form analysis as well as to brain modeling in biology and psychology.  Statistical decision and estimation, which are the main subjects of this book, are regarded as fundamental to the study of pattern recognition.  This book is appropriate as a text for introductory courses in pattern recognition and as a reference book for workers in the field.  Each chapter contains computer projects as well as exercises.},
	language = {English},
	publisher = {Academic Press},
	author = {Fukunaga, Keinosuke},
	month = oct,
	year = {1990}
}

@article{eckart_approximation_1936,
	title = {The approximation of one matrix by another of lower rank},
	volume = {1},
	issn = {0033-3123, 1860-0980},
	doi = {10.1007/BF02288367},
	abstract = {The mathematical problem of approximating one matrix by another of lower rank is closely related to the fundamental postulate of factor-theory. When formulated as a least-squares problem, the normal equations cannot be immediately written down, since the elements of the approximate matrix are not independent of one another. The solution of the problem is simplified by first expressing the matrices in a canonic form. It is found that the problem always has a solution which is usually unique. Several conclusions can be drawn from the form of this solution. A hypothetical interpretation of the canonic components of a score matrix is discussed.},
	language = {en},
	number = {3},
	urldate = {2016-07-12},
	journal = {Psychometrika},
	author = {Eckart, Carl and Young, Gale},
	year = {1936},
	pages = {211--218},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\D8VM55XM\\Eckart and Young - The approximation of one matrix by another of lowe.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\6CIVDI5G\\BF02288367.html:text/html}
}

@article{zhang_fault_2011,
	title = {Fault diagnosis of nonlinear processes using multiscale {KPCA} and multiscale {KPLS}},
	volume = {66},
	issn = {0009-2509},
	doi = {10.1016/j.ces.2010.10.008},
	abstract = {New approaches are proposed for nonlinear process monitoring and fault diagnosis based on kernel principal component analysis (KPCA) and kernel partial least analysis (KPLS) models at different scales, which are called multiscale KPCA (MSKPCA) and multiscale KPLS (MSKPLS). KPCA and KPLS are applied to these multiscale data to capture process variable correlations occurring at different scales. Main contribution of the paper is to propose nonlinear fault diagnosis methods based on multiscale contribution plots. In particular, the nonlinear scores of the variables at each scale are derived. These nonlinear scale contributions can be computed, which is very useful in diagnosing faults that occur mainly at a single scale. The proposed methods are applied to process monitoring of a continuous annealing process and fused magnesium furnace. Application results indicate that the proposed approach effectively captures the complex relations in the process and improves the diagnosis ability.},
	number = {1},
	urldate = {2016-10-17},
	journal = {Chem. Eng. Sci.},
	author = {Zhang, Yingwei and Ma, Chi},
	month = jan,
	year = {2011},
	keywords = {Control, Design, Fault detection, fault diagnosis, Multiscale modeling, Process monitoring},
	pages = {64--72},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\KZ7U9XT9\\Zhang and Ma - 2011 - Fault diagnosis of nonlinear processes using multi.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\NPP9JW8D\\S0009250910005944.html:text/html}
}

@article{paul_comparing_2013,
	title = {Comparing and contrasting traditional membrane bioreactor models with novel ones based on time series analysis},
	volume = {3},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	doi = {10.3390/membranes3010016},
	abstract = {The computer modelling and simulation of wastewater treatment plant and their specific technologies, such as membrane bioreactors (MBRs), are becoming increasingly useful to consultant engineers when designing, upgrading, retrofitting, operating and controlling these plant. This research uses traditional phenomenological mechanistic models based on MBR filtration and biochemical processes to measure the effectiveness of alternative and novel time series models based upon input–output system identification methods. Both model types are calibrated and validated using similar plant layouts and data sets derived for this purpose. Results prove that although both approaches have their advantages, they also have specific disadvantages as well. In conclusion, the MBR plant designer and/or operator who wishes to use good quality, calibrated models to gain a better understanding of their process, should carefully consider which model type is selected based upon on what their initial modelling objectives are. Each situation usually proves unique.},
	language = {en},
	number = {1},
	urldate = {2016-10-14},
	journal = {Membranes},
	author = {Paul, Parneet},
	month = feb,
	year = {2013},
	keywords = {membrane bioreactor, modelling, Time Series Analysis, Wastewater treatment},
	pages = {16--23},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\ZKUNDMGB\\Paul - 2013 - Comparing and Contrasting Traditional Membrane Bio.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\CTASQM3X\\16.html:text/html}
}

@article{hennig_asymmetric_2004,
	title = {Asymmetric linear dimension reduction for classification},
	volume = {13},
	issn = {1061-8600},
	doi = {10.1198/106186004X12740},
	number = {4},
	urldate = {2016-06-22},
	journal = {J. Comput. Graph. Stat.},
	author = {Hennig, Christian},
	month = dec,
	year = {2004},
	pages = {930--945},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\QXTXSXJ9\\106186004X12740.html:text/html}
}

@article{kruger_introduction_2005,
	series = {Selected {Papers} {Presented} at the {Symposium} on {Modeling} of {Complex} {ProcessesSymposium} on {Modeling} of {Complex} {ProcessesEngineering}},
	title = {Introduction of a nonlinearity measure for principal component models},
	volume = {29},
	issn = {0098-1354},
	doi = {10.1016/j.compchemeng.2005.05.013},
	abstract = {Although principal component analysis (PCA) is an important tool in standard multivariate data analysis, little interest has been devoted to assessing whether the underlying relationship within a given variable set can be described by a linear PCA model or whether nonlinear PCA must be utilized. This paper addresses this deficiency by introducing a nonlinearity measure for principal component models. The measure is based on the following two principles: (i) the range of recorded process operation is divided into smaller regions; and (ii) accuracy bounds are determined for the sum of the discarded eigenvalues. If this sum is within the accuracy bounds for each region, the process is assumed to be linear and vice versa. This procedure is automated through the use of cross-validation. Finally, the paper shows the utility of the new nonlinearity measure using two simulation studies and with data from an industrial melter process.},
	number = {11–12},
	urldate = {2016-10-14},
	journal = {Comput. Chem. Eng.},
	author = {Kruger, Uwe and Antory, David and Hahn, Juergen and Irwin, George W. and McCullough, Geoff},
	month = oct,
	year = {2005},
	keywords = {Accuracy bounds, Disjunct regions, Eigenvalues, Nonlinearity measure, Principal Component Analysis},
	pages = {2355--2362},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\K2UTS9T4\\Kruger et al. - 2005 - Introduction of a nonlinearity measure for princip.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\X3P6K5RR\\S0098135405001377.html:text/html}
}

@book{rao_linear_1973,
	address = {New York},
	series = {Wiley series in probability and mathematical statistics},
	title = {Linear statistical inference and its applications},
	isbn = {978-0-471-70823-0},
	urldate = {2016-07-07},
	publisher = {Wiley},
	author = {Rao, C. Radhakrishna},
	year = {1973},
	keywords = {Mathematical statistics},
	annote = {"A Wiley-Interscience publication."},
	annote = {Includes bibliographies.},
	file = {Hathi Trust Record:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\VT6EBMVW\\000007079.html:text/html}
}

@article{jones_brief_1996,
	title = {A brief survey of bandwidth selection for density estimation},
	volume = {91},
	issn = {0162-1459},
	url = {http://amstat.tandfonline.com/doi/abs/10.1080/01621459.1996.10476701},
	doi = {10.1080/01621459.1996.10476701},
	abstract = {There has been major progress in recent years in data-based bandwidth selection for kernel density estimation. Some “second generation” methods, including plug-in and smoothed bootstrap techniques, have been developed that are far superior to well-known “first generation” methods, such as rules of thumb, least squares cross-validation, and biased cross-validation. We recommend a “solve-the-equation” plug-in bandwidth selector as being most reliable in terms of overall performance. This article is intended to provide easy accessibility to the main ideas for nonexperts.},
	number = {433},
	urldate = {2016-10-14},
	journal = {J. Am. Stat. Assoc.},
	author = {Jones, M. C. and Marron, J. S. and Sheather, S. J.},
	month = mar,
	year = {1996},
	pages = {401--407},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\7I8AMFVS\\01621459.1996.html:text/html}
}

@article{rao_utilization_1948,
	title = {The {Utilization} of {Multiple} {Measurements} in {Problems} of {Biological} {Classification}},
	volume = {10},
	issn = {0035-9246},
	number = {2},
	urldate = {2016-06-22},
	journal = {J. Roy. Stat. Soc. B Met.},
	author = {Rao, C. Radhakrishna},
	year = {1948},
	pages = {159--203}
}

@article{vuono_flexible_2013,
	title = {Flexible hybrid membrane treatment systems for tailored nutrient management: {A} new paradigm in urban wastewater treatment},
	volume = {446},
	issn = {0376-7388},
	shorttitle = {Flexible hybrid membrane treatment systems for tailored nutrient management},
	doi = {10.1016/j.memsci.2013.06.021},
	abstract = {The integration of onsite, decentralized, and satellite wastewater treatment systems into existing urban water infrastructure is an attractive option for recovering water and nutrients locally for multi-purpose reuse. To facilitate wastewater treatment and reuse, tailored to local needs, a hybrid membrane treatment process is proposed that couples sequencing batch reactors with a membrane bioreactor (SBR-MBR). In this study, we explored the flexibility and robustness of this hybrid membrane system at a demonstration-scale under real-world conditions by tightly managing and controlling operation conditions to produce effluent of different qualities for multipurpose reuse. Results suggest that an SBR-MBR treatment configuration is flexible, robust and resilient to changing operating conditions. The hybrid system was capable of producing different effluent qualities within 1 week of changing operating condition with no adverse effects on membrane performance. This work reinforces the need for a new paradigm of water reclamation and reuse and introduces a new treatment concept facilitating tailored nutrient management for a sustainable urban water infrastructure.},
	urldate = {2016-10-17},
	journal = {J. Membrane Sci.},
	author = {Vuono, D. and Henkel, J. and Benecke, J. and Cath, T. Y. and Reid, T. and Johnson, L. and Drewes, J. E.},
	month = nov,
	year = {2013},
	keywords = {Distributed wastewater treatment, Integrated water resource management, membrane bioreactor, Sequencing batch reactor, Tailored water reuse, Water reclamation},
	pages = {34--41},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\C7G4564G\\Vuono et al. - 2013 - Flexible hybrid membrane treatment systems for tai.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\8REMUP9J\\S0376738813005140.html:text/html}
}

@article{ge_improved_2009,
	title = {Improved kernel {PCA}-based monitoring approach for nonlinear processes},
	volume = {64},
	issn = {0009-2509},
	doi = {10.1016/j.ces.2009.01.050},
	abstract = {Conventional kernel principal component analysis (KPCA) may not function well for nonlinear processes, since the Gaussian assumption of the method may be violated through nonlinear and kernel transformation of the original process data. To overcome this deficiency, a statistical local approach is incorporated into KPCA. Through this method, a new score variable which was called improved residual in the statistical local approach is constructed. The new variable approximately follows Gaussian distribution, in spite of which distribution the original data follows. Two new statistics are constructed for process monitoring, with their corresponding confidence limits determined by a χ 2 distribution. Besides of the improvement made on KPCA, the new joint local approach-KPCA method also shows superiority on detection sensitivity, especially for small faults slow changes of the process. The new method is exemplified using a numerical study and also tested in the complicated Tennessee Eastman (TE) benchmark process.},
	number = {9},
	urldate = {2016-10-14},
	journal = {Chem. Eng. Sci.},
	author = {Ge, Zhiqiang and Yang, Chunjie and Song, Zhihuan},
	month = may,
	year = {2009},
	keywords = {Kernel principal component analysis, Nonlinear dynamic, Process control, Safety, Statistical local approach, System engineering},
	pages = {2245--2255},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\8B36W7II\\Ge et al. - 2009 - Improved kernel PCA-based monitoring approach for .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\TKDBCMHB\\S0009250909000669.html:text/html}
}

@article{mjalli_use_2007,
	title = {Use of artificial neural network black-box modeling for the prediction of wastewater treatment plants performance},
	volume = {83},
	issn = {0301-4797},
	doi = {10.1016/j.jenvman.2006.03.004},
	abstract = {A reliable model for any wastewater treatment plant is essential in order to provide a tool for predicting its performance and to form a basis for controlling the operation of the process. This would minimize the operation costs and assess the stability of environmental balance. This process is complex and attains a high degree of nonlinearity due to the presence of bio-organic constituents that are difficult to model using mechanistic approaches. Predicting the plant operational parameters using conventional experimental techniques is also a time consuming step and is an obstacle in the way of efficient control of such processes. In this work, an artificial neural network (ANN) black-box modeling approach was used to acquire the knowledge base of a real wastewater plant and then used as a process model. The study signifies that the ANNs are capable of capturing the plant operation characteristics with a good degree of accuracy. A computer model is developed that incorporates the trained ANN plant model. The developed program is implemented and validated using plant-scale data obtained from a local wastewater treatment plant, namely the Doha West wastewater treatment plant (WWTP). It is used as a valuable performance assessment tool for plant operators and decision makers. The ANN model provided accurate predictions of the effluent stream, in terms of biological oxygen demand (BOD), chemical oxygen demand (COD) and total suspended solids (TSS) when using COD as an input in the crude supply stream. It can be said that the ANN predictions based on three crude supply inputs together, namely BOD, COD and TSS, resulted in better ANN predictions when using only one crude supply input. Graphical user interface representation of the ANN for the Doha West WWTP data is performed and presented.},
	number = {3},
	urldate = {2016-10-14},
	journal = {J. Environ. Manage.},
	author = {Mjalli, Farouq S. and Al-Asheh, S. and Alfadala, H. E.},
	month = may,
	year = {2007},
	keywords = {Artificial neural networks, BOD, COD, Modeling, TSS, Wastewater plant, Wastewater treatment},
	pages = {329--338},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\WCKF7ZNG\\Mjalli et al. - 2007 - Use of artificial neural network black-box modelin.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\GB82JAZ8\\S0301479706001228.html:text/html}
}

@article{zhao_multivariate_2005,
	title = {Multivariate statistical process monitoring using robust nonlinear principal component analysis},
	volume = {10},
	issn = {1007-0214},
	doi = {10.1016/S1007-0214(05)70122-X},
	abstract = {The principal component analysis (PCA) algorithm is widely applied in a diverse range of fields for performance assessment, fault detection, and diagnosis. However, in the presence of noise and gross errors, the nonlinear PCA (NLPCA) using autoassociative bottle-neck neural networks is so sensitive that the obtained model differs significantly from the underlying system. In this paper, a robust version of NLPCA is introduced by replacing the generally used error criterion mean squared error with a mean log squared error. This is followed by a concise analysis of the corresponding training method. A novel multivariate statistical process monitoring (MSPM) scheme incorporating the proposed robust NLPCA technique is then investigated and its efficiency is assessed through application to an industrial fluidized catalytic cracking plant. The results demonstrate that, compared with NLPCA, the proposed approach can effectively reduce the number of false alarms and is, hence, expected to better monitor real-world processes.},
	number = {5},
	urldate = {2016-10-17},
	journal = {Tsinghua Sci. Technol.},
	author = {Zhao, Shijian and Xu, Yongmao},
	month = oct,
	year = {2005},
	keywords = {autoassociative networks, fluidized catalytic cracking unit (FCCU), multivariate statistical process monitoring (MSPM), robust nonlinear principal component analysis},
	pages = {582--586},
	file = {ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\3CG2Q94G\\S100702140570122X.html:text/html}
}

@article{cook_covariance_2008,
	title = {Covariance reducing models: {An} alternative to spectral modelling of covariance matrices},
	volume = {95},
	issn = {0006-3444, 1464-3510},
	shorttitle = {Covariance reducing models},
	doi = {10.1093/biomet/asn052},
	abstract = {We introduce covariance reducing models for studying the sample covariance matrices of a random vector observed in different populations. The models are based on reducing the sample covariance matrices to an informational core that is sufficient to characterize the variance heterogeneity among the populations. They possess useful equivariance properties and provide a clear alternative to spectral models for covariance matrices.},
	language = {en},
	number = {4},
	urldate = {2016-09-28},
	journal = {Biometrika},
	author = {Cook, R. Dennis and Forzani, Liliana},
	month = dec,
	year = {2008},
	keywords = {Central subspace, dimension reduction, Envelopes, Grassmann manifolds, Reducing subspaces},
	pages = {799--812},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\37JWFZQN\\Cook and Forzani - 2008 - Covariance reducing models An alternative to spec.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\3CG6SMA9\\799.html:text/html}
}

@article{ku_disturbance_1995,
	series = {{InCINC} '94 {Selected} papers from the {First} {International} {Chemometrics} {Internet} {Conference}},
	title = {Disturbance detection and isolation by dynamic principal component analysis},
	volume = {30},
	issn = {0169-7439},
	doi = {10.1016/0169-7439(95)00076-3},
	abstract = {In this paper we extend previous work by ourselves and other researchers in the use of principal component analysis (PCA) for statistical process control in chemical processes. PCA has been used by several authors to develop techniques to monitor chemical processes and detect the presence of disturbances [1–5]. In past work, we have developed methods which not only detect disturbances, but isolate the sources of the disturbances [4]. The approach was based on static PCA models, T2 and Q charts [6], and a model bank of possible disturbances. In this paper we use a well-known ‘time lag shift’ method to include dynamic behavior in the PCA model. The proposed dynamic PCA model development procedure is desirable due to its simplicity of construction, and is not meant to replace the many well-known and more elegant procedures used in model identification. While dynamic linear model identification, and time lag shift are well known methods in model building, this is the first application we are aware of in the area of statistical process monitoring. Extensive testing on the Tennessee Eastman process simulation [7] demonstrates the effectiveness of the proposed methodology.},
	number = {1},
	urldate = {2016-10-14},
	journal = {Chemometr. Intell. Lab.},
	author = {Ku, Wenfu and Storer, Robert H. and Georgakis, Christos},
	month = nov,
	year = {1995},
	keywords = {Dynamic multivariate statistical process control},
	pages = {179--196},
	file = {ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\9W6IHS98\\0169743995000763.html:text/html}
}

@book{bache_uci_2013,
	title = {{UCI} {Machine} {Learning} {Repository}},
	publisher = {University of California, Irvine, School of Information and Computer Sciences},
	author = {Bache, Kevin and Lichman, Moshe},
	year = {2013}
}

@article{choi_fault_2005,
	title = {Fault detection and identification of nonlinear processes based on kernel {PCA}},
	volume = {75},
	issn = {0169-7439},
	doi = {10.1016/j.chemolab.2004.05.001},
	abstract = {A new fault detection and identification method based on kernel principal component analysis (PCA) is described. In the past, numerous PCA-based statistical process monitoring methods have been developed and applied to various chemical processes. However, these previous methods assume that the monitored process is linear, whereas most of the chemical reactions in chemical processes are nonlinear. For such nonlinear systems, PCA-based monitoring has proved inefficient and problematic, prompting the development of several nonlinear PCA methods. In this paper, we propose a new nonlinear PCA-based method that uses kernel functions, and we compare the proposed method with previous methods. A unified fault detection index is developed based on the energy approximation concept. In particular, a new approach to fault identification, which is a challenging problem in nonlinear PCA, is formulated based on a robust reconstruction error calculation. The proposed monitoring method was applied to two simple nonlinear processes and the simulated continuous stirred tank reactor (CSTR) process. The monitoring results confirm that the proposed methodology affords credible fault detection and identification.},
	number = {1},
	urldate = {2016-10-14},
	journal = {Chemometr. Intell. Lab.},
	author = {Choi, Sang Wook and Lee, Changkyu and Lee, Jong-Min and Park, Jin Hyun and Lee, In-Beum},
	month = jan,
	year = {2005},
	keywords = {Data reconstruction, Fault detection and isolation, Kernel principal component analysis, Monitoring statistics},
	pages = {55--67},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\KTMJ4JV9\\Choi et al. - 2005 - Fault detection and identification of nonlinear pr.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\GBANRK6X\\S0169743904001224.html:text/html}
}

@article{hastie_gene_2000,
	title = {'{Gene} shaving' as a method for identifying distinct sets of genes with similar expression patterns},
	volume = {1},
	issn = {1465-6906},
	abstract = {Background:
Large gene expression studies, such as those conducted using DNA arrays, often provide millions of different pieces of data. To address the problem of analyzing such data, we describe a statistical method, which we have called 'gene shaving'. The method identifies subsets of genes with coherent expression patterns and large variation across conditions. Gene shaving differs from hierarchical clustering and other widely used methods for analyzing gene expression studies in that genes may belong to more than one cluster, and the clustering may be supervised by an outcome measure. The technique can be 'unsupervised', that is, the genes and samples are treated as unlabeled, or partially or fully supervised by using known properties of the genes or samples to assist in finding meaningful groupings.

Results:
We illustrate the use of the gene shaving method to analyze gene expression measurements made on samples from patients with diffuse large B-cell lymphoma. The method identifies a small cluster of genes whose expression is highly predictive of survival.

Conclusions:
The gene shaving method is a potentially useful tool for exploration of gene expression data and identification of interesting clusters of genes worth further investigation.},
	number = {2},
	urldate = {2017-01-27},
	journal = {Genome Biol.},
	author = {Hastie, Trevor and Tibshirani, Robert and Eisen, Michael B and Alizadeh, Ash and Levy, Ronald and Staudt, Louis and Chan, Wing C and Botstein, David and Brown, Patrick},
	year = {2000},
	pmid = {11178228},
	pmcid = {PMC15015},
	pages = {research0003.1--research0003.21},
	file = {PubMed Central Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\Z7UXJGZQ\\Hastie et al. - 2000 - 'Gene shaving' as a method for identifying distinc.pdf:application/pdf}
}

@article{fisher_use_1936,
	title = {The use of multiple measurements in taxonomic problems},
	volume = {7},
	copyright = {1936 Blackwell Publishing Ltd/University College London},
	issn = {2050-1439},
	doi = {10.1111/j.1469-1809.1936.tb02137.x},
	abstract = {The articles published by the Annals of Eugenics (1925–1954) have been made available online as an historical archive intended for scholarly use. The work of eugenicists was often pervaded by prejudice against racial, ethnic and disabled groups. The online publication of this material for scholarly research purposes is not an endorsement of those views nor a promotion of eugenics in any way.},
	language = {en},
	number = {2},
	urldate = {2016-06-22},
	journal = {Ann. Eugenic.},
	author = {Fisher, R. A.},
	month = sep,
	year = {1936},
	pages = {179--188},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\42K2NGWU\\Fisher - 1936 - The Use of Multiple Measurements in Taxonomic Prob.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\3ATK79BV\\abstract.html:text/html}
}

@article{chetouani_neural_2007,
	title = {A neural network approach for the real-time detection of faults},
	volume = {22},
	issn = {1436-3240, 1436-3259},
	doi = {10.1007/s00477-007-0123-4},
	abstract = {Fault detection is an essential part of the operation of any chemical plant. Early detection of faults is important in chemical industry since a lot of damage and loss can result before a fault present in the system is detected. Even though fault detection algorithms are designed and implemented for quickly detecting incidents, most these algorithms do not have an optimal property in terms of detection delay with respect to false alarm rate. Based on the optimization property of cumulative sum (CUSUM), a real-time system for detecting changes in dynamic systems is designed in this paper. This work is motivated by combining two fault detection (FD) strategies; a simplified procedure of the incident detection problem is formulated by using both the artificial neural networks (ANN) and the CUSUM statistical test (Page–Hinkley test). The design of a model-based residual generator is intended to reveal any drift from the normal behavior of the process. In order to obtain a reliable model for the normal process dynamics, the neural black-box modeling by means of a nonlinear auto-regressive with eXogenous input (NARX) model has been chosen in this study. This paper also shows the choice and the performance of the neural network in the training and test phases. After describing the system architecture and the proposed methodology of the fault detection, we present a realistic application in order to show the technique’s potential. The purpose is to develop and test the fault detection method on a real incident data, to detect the change presence, and pinpoint the moment it occurred. The experimental results demonstrate the robustness of the FD method.},
	language = {en},
	number = {3},
	urldate = {2016-10-14},
	journal = {Stoch. Environ. Res. Risk Assess.},
	author = {Chetouani, Yahya},
	month = mar,
	year = {2007},
	pages = {339--349},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\47CEUPBJ\\Chetouani - 2007 - A neural network approach for the real-time detect.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\WUJXQIVD\\s00477-007-0123-4.html:text/html}
}

@article{norman_slow_1968,
	title = {Slow {Learning}},
	volume = {21},
	issn = {2044-8317},
	doi = {10.1111/j.2044-8317.1968.tb00406.x},
	abstract = {Learning will be slow if the quantity that represents the state of learning changes by small steps or with small probability on each experimental trial. Approximations to the distribution of this quantity for both types of slow learning are obtained. These approximations are applicable to a wide variety of models.},
	language = {en},
	number = {2},
	urldate = {2017-01-21},
	journal = {British Journal of Mathematical and Statistical Psychology},
	author = {Norman, M. Frank},
	month = nov,
	year = {1968},
	pages = {141--159},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\2KP4J6BE\\abstract.html:text/html}
}

@article{wold_principal_1987,
	series = {Proceedings of the {Multivariate} {Statistical} {Workshop} for {Geologists} and {Geochemists}},
	title = {Principal component analysis},
	volume = {2},
	issn = {0169-7439},
	doi = {10.1016/0169-7439(87)80084-9},
	abstract = {Principal component analysis of a data matrix extracts the dominant patterns in the matrix in terms of a complementary set of score and loading plots. It is the responsibility of the data analyst to formulate the scientific issue at hand in terms of PC projections, PLS regressions, etc. Ask yourself, or the investigator, why the data matrix was collected, and for what purpose the experiments and measurements were made. Specify before the analysis what kinds of patterns you would expect and what you would find exciting. The results of the analysis depend on the scaling of the matrix, which therefore must be specified. Variance scaling, where each variable is scaled to unit variance, can be recommended for general use, provided that almost constant variables are left unscaled. Combining different types of variables warrants blockscaling. In the initial analysis, look for outliers and strong groupings in the plots, indicating that the data matrix perhaps should be “polished” or whether disjoint modeling is the proper course. For plotting purposes, two or three principal components are usually sufficient, but for modeling purposes the number of significant components should be properly determined, e.g. by cross-validation. Use the resulting principal components to guide your continued investigation or chemical experimentation, not as an end in itself.},
	number = {1},
	urldate = {2016-10-17},
	journal = {Chemometr. Intell. Lab.},
	author = {Wold, Svante and Esbensen, Kim and Geladi, Paul},
	month = aug,
	year = {1987},
	pages = {37--52},
	file = {ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\5NR3BGXD\\0169743987800849.html:text/html}
}

@article{van_sprang_critical_2002,
	title = {Critical evaluation of approaches for on-line batch process monitoring},
	volume = {57},
	issn = {0009-2509},
	doi = {10.1016/S0009-2509(02)00338-X},
	abstract = {Since the introduction of batch process monitoring using component models in 1992, different approaches for statistical batch process monitoring have been suggested in the literature. This is the first evaluation of five proposed approaches so far. The differences and similarities between the approaches are highlighted. The derivation of control charts for these approaches are discussed. A control chart should give a fast and reliable detection of disturbances in the process. These features are evaluated for each approach by means of two performance indices. First, the action signal time for various disturbed batches is tested. Secondly, the probability of a false warning in a control chart is computed. In order to evaluate the five approaches, five different data sets are studied: one simulation of a batch process, three batch processes obtained from industry and one laboratory spectral data set. The obtained results for the performance indices are summarised and discussed. Recommendations helpful for practical use are given.},
	number = {18},
	urldate = {2016-10-17},
	journal = {Chem. Eng. Sci.},
	author = {van Sprang, Eric N. M and Ramaker, Henk-Jan and Westerhuis, Johan A and Gurden, Stephen P and Smilde, Age K},
	month = sep,
	year = {2002},
	keywords = {Action signal time, Batch process monitoring, Control chart, On-line monitoring, Statistical process control, Type I error},
	pages = {3979--3991},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\KVAZ7Z54\\van Sprang et al. - 2002 - Critical evaluation of approaches for on-line batc.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\SWB32762\\S000925090200338X.html:text/html}
}

@article{haff_estimation_1979,
	title = {Estimation of the inverse covariance matrix: random mixtures of the inverse wishart matrix and the identity},
	volume = {7},
	issn = {0090-5364},
	shorttitle = {Estimation of the {Inverse} {Covariance} {Matrix}},
	abstract = {Let Sp × p have a nonsingular Wishart distribution with unknown matrix Σ and k degrees of freedom. For two different loss functions, estimators of Σ-1 are given which dominate the obvious estimators \$aS{\textasciicircum}\{-1\}, 0 {\textless} a {\textbackslash}leqslant k - p - 1\$. Our class of estimators C includes random mixtures of S-1 and I. A subclass \${\textbackslash}mathscr\{C\}\_0 {\textbackslash}subset {\textbackslash}mathscr\{C\}\$ was given by Haff. Here, we show that any member of C0 is dominated in C. Some troublesome aspects of the estimation problem are discussed, and the theory is supplemented by simulation results.},
	number = {6},
	urldate = {2016-06-22},
	journal = {Ann. Stat.},
	author = {Haff, L. R.},
	year = {1979},
	pages = {1264--1276}
}

@article{ounpraseuth_linear_2015,
	title = {Linear dimension reduction for multiple heteroscedastic multivariate normal populations},
	volume = {05},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	doi = {10.4236/ojs.2015.54033},
	abstract = {For the case where all multivariate normal parameters are known, we derive a new linear dimension reduction (LDR) method to determine a low-dimensional subspace that preserves or nearly preserves the original feature-space separation of the individual populations and the Bayes probability of misclassification. We also give necessary and sufficient conditions which provide the smallest reduced dimension that essentially retains the Bayes probability of misclassification from the original full-dimensional space in the reduced space. Moreover, our new LDR procedure requires no computationally expensive optimization procedure. Finally, for the case where parameters are unknown, we devise a LDR method based on our new theorem and compare our LDR method with three competing LDR methods using Monte Carlo simulations and a parametric bootstrap based on real data.},
	language = {en},
	number = {04},
	urldate = {2016-06-22},
	journal = {OJS},
	author = {Ounpraseuth, Songthip T. and Young, Phil D. and Van Zyl, Johanna S. and Nelson, Tyler W. and Young, Dean M.},
	month = may,
	year = {2015},
	pages = {311},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\TH8XQ62W\\Ounpraseuth et al. - 2015 - Linear Dimension Reduction for Multiple Heterosced.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\F9DG9S95\\PaperInformation.html:text/html}
}

@article{skold_bias_2001,
	title = {A bias correction for cross-validation bandwidth selection when a kernel estimate is based on dependent data},
	volume = {22},
	issn = {1467-9892},
	doi = {10.1111/1467-9892.00237},
	abstract = {Least-squares cross-validation (LSCV) bandwidth selection for kernel density estimation has been shown to underestimate the optimal bandwidth if data are positively correlated. We calculate the asymptotic bias for the LSCV criterion under a continuous-time model and apply it as a correction term to discrete-time data that can be modeled as a smooth continuous-time process sampled at a high rate.},
	language = {en},
	number = {4},
	urldate = {2016-10-17},
	journal = {J. Time Ser. Anal.},
	author = {Skold, Martin},
	month = jul,
	year = {2001},
	keywords = {bandwidth selection, cross-validation, dependent data, kernel estimate, Nonparametric density estimation},
	pages = {493--503},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\7VKAGDI5\\Skold - 2001 - A Bias Correction for Cross-validation Bandwidth S.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\4TZVTRE3\\abstract.html:text/html}
}

@book{johnson_applied_2002,
	address = {Upper Saddle River, N.J},
	edition = {5th ed},
	title = {Applied multivariate statistical analysis},
	isbn = {978-0-13-092553-4},
	publisher = {Prentice Hall},
	author = {Johnson, Richard A. and Wichern, Dean W.},
	year = {2002},
	keywords = {Multivariate analysis}
}

@book{rojas_neural_2013,
	title = {Neural {Networks}: {A} {Systematic} {Introduction}},
	isbn = {978-3-642-61068-4},
	shorttitle = {Neural {Networks}},
	abstract = {Neural networks are a computing paradigm that is finding increasing attention among computer scientists. In this book, theoretical laws and models previously scattered in the literature are brought together into a general theory of artificial neural nets. Always with a view to biology and starting with the simplest nets, it is shown how the properties of models change when more general computing elements and net topologies are introduced. Each chapter contains examples, numerous illustrations, and a bibliography. The book is aimed at readers who seek an overview of the field or who wish to deepen their knowledge. It is suitable as a basis for university courses in neurocomputing.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Rojas, Raul},
	month = jun,
	year = {2013},
	keywords = {Computers / Computer Simulation, Computers / Computer Vision \& Pattern Recognition, Computers / Desktop Applications / Design \& Graphics, Computers / Intelligence (AI) \& Semantics, Computers / Machine Theory, Computers / Optical Data Processing, Computers / Software Development \& Engineering / General, Computers / Systems Architecture / General, Computers / User Interfaces, Science / Life Sciences / Biology, Science / Life Sciences / General}
}

@article{hiden_non-linear_1999,
	title = {Non-linear principal components analysis using genetic programming},
	volume = {23},
	issn = {0098-1354},
	doi = {10.1016/S0098-1354(98)00284-1},
	abstract = {Principal components analysis (PCA) is a standard statistical technique, which is frequently employed in the analysis of large highly correlated data sets. As it stands, PCA is a linear technique which can limit its relevance to the non-linear systems frequently encountered in the chemical process industries. Several attempts to extend linear PCA to cover non-linear data sets have been made, and will be briefly reviewed in this paper. We propose a symbolically oriented technique for non-linear PCA, which is based on the genetic programming (GP) paradigm. Its applicability will be demonstrated using two simple non-linear systems and data collected from an industrial distillation column.},
	number = {3},
	urldate = {2016-10-14},
	journal = {Comput. Chem. Eng.},
	author = {Hiden, H. G. and Willis, M. J. and Tham, M. T. and Montague, G. A.},
	month = feb,
	year = {1999},
	keywords = {Data analysis, Genetic programming, Multivariate statistics},
	pages = {413--425},
	file = {ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\4HESVGT6\\S0098135498002841.html:text/html}
}

@article{sheather_reliable_1991,
	title = {A reliable data-based bandwidth selection method for kernel density estimation},
	volume = {53},
	issn = {0035-9246},
	abstract = {We present a new method for data-based selection of the bandwidth in kernel density estimation which has excellent properties. It improves on a recent procedure of Park and Marron (which itself is a good method) in various ways. First, the new method has superior theoretical performance; second, it also has a computational advantage; third, the new method has reliably good performance for smooth densities in simulations, performance that is second to none in the existing literature. These methods are based on choosing the bandwidth to (approximately) minimize good quality estimates of the mean integrated squared error. The key to the success of the current procedure is the reintroduction of a non-stochastic term which was previously omitted together with use of the bandwidth to reduce bias in estimation without inflating variance.},
	number = {3},
	urldate = {2016-10-17},
	journal = {J. Roy. Stat. Soc. B Met.},
	author = {Sheather, S. J. and Jones, M. C.},
	year = {1991},
	pages = {683--690}
}

@article{miao_nonlinear_2013,
	title = {Nonlinear fault detection based on locally linear embedding},
	volume = {11},
	issn = {1672-6340, 1993-0623},
	doi = {10.1007/s11768-013-2102-2},
	abstract = {In this paper, a new nonlinear fault detection technique based on locally linear embedding (LLE) is developed. LLE can efficiently compute the low-dimensional embedding of the data with the local neighborhood structure information preserved. In this method, a data-dependent kernel matrix which can reflect the nonlinear data structure is defined. Based on the kernel matrix, the Nyström formula makes the mapping extended to the testing data possible. With the kernel view of the LLE, two monitoring statistics are constructed. Together with the out of sample extensions, LLE is used for nonlinear fault detection. Simulation cases were studied to demonstrate the performance of the proposed method.},
	language = {en},
	number = {4},
	urldate = {2016-10-14},
	journal = {J. Control Theory Appl.},
	author = {Miao, Aimin and Song, Zhihuan and Ge, Zhiqiang and Zhou, Le and Wen, Qiaojun},
	month = oct,
	year = {2013},
	pages = {615--622},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\7DJWVTD3\\Miao et al. - 2013 - Nonlinear fault detection based on locally linear .pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\D264F9SN\\s11768-013-2102-2.html:text/html}
}

@book{gutman_mathematical_1986,
	address = {Berlin, Heidelberg},
	title = {Mathematical {Concepts} in {Organic} {Chemistry}},
	isbn = {978-3-642-70984-5 978-3-642-70982-1},
	language = {en},
	urldate = {2016-08-01},
	publisher = {Springer Berlin Heidelberg},
	author = {Gutman, Ivan and Polansky, Oskar E.},
	year = {1986}
}

@article{hartwig_reverse_1986,
	title = {The reverse order law revisited},
	volume = {76},
	issn = {0024-3795},
	doi = {10.1016/0024-3795(86)90226-0},
	abstract = {Necessary and sufficient conditions are given for the triple reverse order law (ABC)† = C†B†A† to hold. Some special cases are considered.},
	urldate = {2016-07-06},
	journal = {Linear. Algebra. Appl.},
	author = {Hartwig, R. E.},
	month = apr,
	year = {1986},
	pages = {241--246},
	file = {ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\37Q52RI5\\0024379586902260.html:text/html}
}

@article{loog_linear_2004,
	title = {Linear dimensionality reduction via a heteroscedastic extension of {LDA}: the {Chernoff} criterion},
	volume = {26},
	issn = {0162-8828},
	shorttitle = {Linear dimensionality reduction via a heteroscedastic extension of {LDA}},
	doi = {10.1109/TPAMI.2004.13},
	abstract = {We propose an eigenvector-based heteroscedastic linear dimension reduction (LDR) technique for multiclass data. The technique is based on a heteroscedastic two-class technique which utilizes the so-called Chernoff criterion, and successfully extends the well-known linear discriminant analysis (LDA). The latter, which is based on the Fisher criterion, is incapable of dealing with heteroscedastic data in a proper way. For the two-class case, the between-class scatter is generalized so to capture differences in (co)variances. It is shown that the classical notion of between-class scatter can be associated with Euclidean distances between class means. From this viewpoint, the between-class scatter is generalized by employing the Chernoff distance measure, leading to our proposed heteroscedastic measure. Finally, using the results from the two-class case, a multiclass extension of the Chernoff criterion is proposed. This criterion combines separation information present in the class mean as well as the class covariance matrices. Extensive experiments and a comparison with similar dimension reduction techniques are presented.},
	language = {eng},
	number = {6},
	journal = {IEEE Trans. Pattern. Anal. Mach. Intell.},
	author = {Loog, Marco and Duin, Robert P. W.},
	month = jun,
	year = {2004},
	pmid = {18579934},
	keywords = {Algorithms, Artificial Intelligence, Computer Simulation, Information Storage and Retrieval, Linear Models, Pattern Recognition, Automated, Reproducibility of Results, Sensitivity and Specificity},
	pages = {732--739}
}

@article{cook_sliced_1991,
	title = {Sliced inverse regression for dimension reduction: comment},
	volume = {86},
	issn = {0162-1459},
	shorttitle = {Sliced {Inverse} {Regression} for {Dimension} {Reduction}},
	doi = {10.2307/2290564},
	number = {414},
	urldate = {2016-06-22},
	journal = {J. Am. Stat. Assoc.},
	author = {Cook, R. Dennis and Weisberg, Sanford},
	year = {1991},
	pages = {328--332},
	file = {JSTOR Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\V8BRVCMI\\Cook and Weisberg - 1991 - Sliced Inverse Regression for Dimension Reduction.pdf:application/pdf}
}

@book{lutkepohl_new_2005,
	address = {Berlin : New York},
	title = {New {Introduction} to {Multiple} {Time} {Series} {Analysis}},
	isbn = {978-3-540-40172-8},
	publisher = {Springer},
	author = {Lutkepohl, Helmut},
	year = {2005},
	note = {OCLC: 61028971},
	keywords = {Time-series analysis}
}

@incollection{de_ridder_supervised_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Supervised {Locally} {Linear} {Embedding}},
	copyright = {©2003 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-40408-8 978-3-540-44989-8},
	abstract = {Locally linear embedding (LLE) is a recently proposed method for unsupervised nonlinear dimensionality reduction. It has a number of attractive features: it does not require an iterative algorithm, and just a few parameters need to be set. Two extensions of LLE to supervised feature extraction were independently proposed by the authors of this paper. Here, both methods are unified in a common framework and applied to a number of benchmark data sets. Results show that they perform very well on high-dimensional data which exhibits a manifold structure.},
	language = {en},
	number = {2714},
	urldate = {2016-10-17},
	booktitle = {Artificial {Neural} {Networks} and {Neural} {Information} {Processing} — {ICANN}/{ICONIP} 2003},
	publisher = {Springer Berlin Heidelberg},
	author = {de Ridder, Dick and Kouropteva, Olga and Okun, Oleg and Pietikainen, Matti and Duin, Robert P. W.},
	editor = {Kaynak, Okyay and Alpaydin, Ethem and Oja, Erkki and Xu, Lei},
	year = {2003},
	note = {DOI: 10.1007/3-540-44989-2\_40},
	keywords = {Artificial Intelligence (incl. Robotics), Computation by Abstract Devices, Computer Communication Networks, Database Management, Science, general, Special Purpose and Application-Based Systems},
	pages = {333--341},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\9MR8D4I3\\3-540-44989-2_40.html:text/html}
}

@article{lee_statistical_2004,
	title = {Statistical process monitoring with independent component analysis},
	volume = {14},
	issn = {0959-1524},
	doi = {10.1016/j.jprocont.2003.09.004},
	abstract = {In this paper we propose a new statistical method for process monitoring that uses independent component analysis (ICA). ICA is a recently developed method in which the goal is to decompose observed data into linear combinations of statistically independent components [1,2]. Such a representation has been shown to capture the essential structure of the data in many applications, including signal separation and feature extraction. The basic idea of our approach is to use ICA to extract the essential independent components that drive a process and to combine them with process monitoring techniques. I2, Ie2 and SPE charts are proposed as on-line monitoring charts and contribution plots of these statistical quantities are also considered for fault identification. The proposed monitoring method was applied to fault detection and identification in both a simple multivariate process and the simulation benchmark of the biological wastewater treatment process, which is characterized by a variety of fault sources with non-Gaussian characteristics. The simulation results clearly show the power and advantages of ICA monitoring in comparison to PCA monitoring.},
	number = {5},
	urldate = {2016-10-14},
	journal = {J. Process Contr.},
	author = {Lee, Jong-Min and Yoo, ChangKyoo and Lee, In-Beum},
	month = aug,
	year = {2004},
	keywords = {Fault detection, Independent component analysis, Kernel density estimation, Process monitoring, Wastewater treatment process},
	pages = {467--485},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\JRAFHNXP\\Lee et al. - 2004 - Statistical process monitoring with independent co.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\HU4W8DJE\\S0959152403000994.html:text/html}
}

@article{pavlenko_effect_2001,
	title = {Effect of dimensionality on discrimination},
	volume = {35},
	issn = {0233-1888},
	doi = {10.1080/02331880108802731},
	abstract = {Discrimination problems in a high-dimensional setting is considered. New results are concerned with the role of the dimensionality in the performance of the discrimination procedure. Assuming that data consist of a block structure two different asymptotic approaches are presented. These approaches are characterized by different types of relations between the dimensionality and the size of the training samples. Asymptotic expressions for the error probabilities are obtained and a consistent approximation of the discriminant function is proposed. Throughout the paper the importance of the dimensionality in the asymptotic analysis is stressed.},
	number = {3},
	urldate = {2016-12-21},
	journal = {Statistics},
	author = {Pavlenko, Tatjana and Rosen, Dietrich Von},
	month = jan,
	year = {2001},
	keywords = {Discriminant Analysis, Growing dimension asymptotic, Likelihood based discrimination, Limiting error probability, Plug-in estimator},
	pages = {191--213},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\R9XSMVBT\\02331880108802731.html:text/html}
}

@article{westerhuis_generalized_2000,
	title = {Generalized contribution plots in multivariate statistical process monitoring},
	volume = {51},
	issn = {0169-7439},
	doi = {10.1016/S0169-7439(00)00062-9},
	abstract = {This paper discusses contribution plots for both the D-statistic and the Q-statistic in multivariate statistical process control of batch processes. Contributions of process variables to the D-statistic are generalized to any type of latent variable model with or without orthogonality constraints. The calculation of contributions to the Q-statistic is discussed. Control limits for both types of contributions are introduced to show the relative importance of a contribution compared to the contributions of the corresponding process variables in the batches obtained under normal operating conditions. The contributions are introduced for off-line monitoring of batch processes, but can easily be extended to on-line monitoring and to continuous processes, as is shown in this paper.},
	number = {1},
	urldate = {2016-10-17},
	journal = {Chemometr. Intell. Lab.},
	author = {Westerhuis, Johan A. and Gurden, Stephen P. and Smilde, Age K.},
	month = may,
	year = {2000},
	keywords = {Contribution plots, Control limits, D-statistic, Q-statistic, Statistical process control},
	pages = {95--114},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\WPWKQSWK\\Westerhuis et al. - 2000 - Generalized contribution plots in multivariate sta.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\U7742AUF\\S0169743900000629.html:text/html}
}

@book{carpenter_pattern_1991,
	title = {Pattern {Recognition} by {Self}-organizing {Neural} {Networks}},
	isbn = {978-0-262-03176-9},
	abstract = {Pattern Recognition by Self-Organizing Neural Networks presentsthe most recent advances in an area of research that is becoming vitally important in the fields ofcognitive science, neuroscience, artificial intelligence, and neural networks in general. The 19articles take up developments in competitive learning and computational maps, adaptive resonancetheory, and specialized architectures and biological connections.Introductorysurvey articles provide a framework for understanding the many models involved in various approachesto studying neural networks. These are followed in Part 2 by articles that form the foundation formodels of competitive learning and computational mapping, and recent articles by Kohonen, applyingthem to problems in speech recognition, and by Hecht-Nielsen, applying them to problems in designingadaptive lookup tables. Articles in Part 3 focus on adaptive resonance theory (ART) networks,selforganizing pattern recognition systems whose top-down template feedback signals guarantee theirstable learning in response to arbitrary sequences of input patterns. In Part 4, articles describeembedding ART modules into larger architectures and provide experimental evidence fromneurophysiology, event-related potentials, and psychology that support the prediction that ARTmechanisms exist in the brain.Contributors: J.-P. Banquet, G.A. Carpenter, S.Grossberg, R. Hecht-Nielsen, T. Kohonen, B. Kosko, T.W. Ryan, N.A. Schmajuk, W. Singer, D. Stork, C.von der Malsburg, C.L. Winter.},
	language = {en},
	publisher = {MIT Press},
	author = {Carpenter, Gail A. and Grossberg, Stephen},
	year = {1991},
	keywords = {Computers / Optical Data Processing, Psychology / Cognitive Psychology, Psychology / Cognitive Psychology \& Cognition}
}

@article{garcia-diaz_monitoring_2010,
	title = {Monitoring and forecasting nitrate concentration in the groundwater using statistical process control and time series analysis: a case study},
	volume = {25},
	issn = {1436-3240, 1436-3259},
	shorttitle = {Monitoring and forecasting nitrate concentration in the groundwater using statistical process control and time series analysis},
	doi = {10.1007/s00477-010-0371-6},
	abstract = {Contaminated water resources have important implications on health and the environment. Nitrate contamination of the groundwater is a serious problem in the European Union. A method based on the statistical process control (SPC) and time series analysis is developed to monitoring and to predict the concentration evolution of nitrate (NO3−) in groundwater. In many pumping wells the NO3−concentration ([NO3−]) increases and approaches or even passes the European Community standard of 50 mg l−1. The objective of this paper is to show the application of statistical process control as a monitoring tool for groundwater pollution from agricultural practices. We propose the autoregressive integrated moving average (ARIMA) model as a management tool to monitoring and reduction of the intrusion of nitrate into the groundwater. This tool should help in setting up useful guidelines for evaluating actual environmental performance against the firm’s environmental objectives and targets and regulatory requirements. We concluded that the statistical process control method may be a potentially important way of monitoring groundwater quality that also permits rapid response to serious increases in pollutants concentrations. In doing so, the paper fills an important gap in the water pollution standards and emerging polices (Water Framework directives).},
	language = {en},
	number = {3},
	urldate = {2016-10-14},
	journal = {Stoch. Environ. Res. Risk Assess.},
	author = {Garcia-Diaz, J. Carlos},
	month = feb,
	year = {2010},
	pages = {331--339},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\WSTZFGZA\\García-Díaz - 2010 - Monitoring and forecasting nitrate concentration i.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\FVVCCWEW\\s00477-010-0371-6.html:text/html}
}

@article{bengio_learning_2004,
	title = {Learning eigenfunctions links spectral embedding and kernel {PCA}},
	volume = {16},
	issn = {08997667},
	abstract = {In this letter, we show a direct relation between spectral embedding methods and kernel principal components analysis and how both are special cases of a more general learning problem: learning the principal eigenfunctions of an operator defined from a kernel and the unknown data-generating density. Whereas spectral embedding methods provided only coordinates for the training points, the analysis justifies a simple extension to out-of-sample examples (the Nyström formula) for multidimensional scaling (MDS), spectral clustering, Laplacian eigenmaps, locally linear embedding (LLE), and Isomap. The analysis provides, for all such spectral embedding methods, the definition of a loss function, whose empirical average is minimized by the traditional algorithms. The asymptotic expected value of that loss defines a generalization performance and clarifies what these algorithms are trying to learn. Experiments with LLE, Isomap, spectral clustering, and MDS show that this out-of-sample embedding formula generalizes well, with a level of error comparable to the effect of small perturbations of the training set on the embedding.},
	number = {10},
	urldate = {2016-10-14},
	journal = {Neural Comput.},
	author = {Bengio, Yoshua and Delalleau, Olivier and Le Roux, Nicolas and Paiement, Jean-Francois and Vincent, Pascal and Ouimet, Marie},
	month = oct,
	year = {2004},
	keywords = {Algorithms, COMPUTER algorithms, COMPUTER programming, COMPUTER science -- Mathematics, EIGENFUNCTIONS, ELECTRONIC data processing, MATHEMATICAL analysis},
	pages = {2197--2219},
	file = {EBSCO Full Text:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\ERMGDHHW\\Bengio et al. - 2004 - Learning Eigenfunctions Links Spectral Embedding a.pdf:application/pdf}
}

@article{schott_determining_1994,
	title = {Determining the dimensionality in sliced inverse regression},
	volume = {89},
	issn = {0162-1459},
	doi = {10.2307/2291210},
	abstract = {A general regression problem is one in which a response variable can be expressed as some function of one or more different linear combinations of a set of explanatory variables as well as a random error term. Sliced inverse regression is a method for determining these linear combinations. In this article we address the problem of determining how many linear combinations are involved. Procedures based on conditional means and conditional covariance matrices, as well as a procedure combining the two approaches, are considered. In each case we develop a test that has an asymptotic chi-squared distribution when the vector of explanatory variables is sampled from an elliptically symmetric distribution.},
	number = {425},
	urldate = {2016-09-27},
	journal = {J. Am. Stat. Assoc.},
	author = {Schott, James R.},
	year = {1994},
	pages = {141--148}
}

@article{friedman_bump_1999,
	title = {Bump hunting in high-dimensional data},
	volume = {9},
	issn = {0960-3174, 1573-1375},
	doi = {10.1023/A:1008894516817},
	abstract = {Many data analytic questions can be formulated as (noisy) optimization problems. They explicitly or implicitly involve finding simultaneous combinations of values for a set of (“input”) variables that imply unusually large (or small) values of another designated (“output”) variable. Specifically, one seeks a set of subregions of the input variable space within which the value of the output variable is considerably larger (or smaller) than its average value over the entire input domain. In addition it is usually desired that these regions be describable in an interpretable form involving simple statements (“rules”) concerning the input values. This paper presents a procedure directed towards this goal based on the notion of “patient” rule induction. This patient strategy is contrasted with the greedy ones used by most rule induction methods, and semi-greedy ones used by some partitioning tree techniques such as CART. Applications involving scientific and commercial data bases are presented.},
	language = {en},
	number = {2},
	urldate = {2017-01-27},
	journal = {Stat. Comput.},
	author = {Friedman, Jerome H. and Fisher, Nicholas I.},
	month = apr,
	year = {1999},
	pages = {123--143},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\DW7UVPWJ\\Friedman and Fisher - 1999 - Bump hunting in high-dimensional data.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\JIHG52SS\\A1008894516817.html:text/html}
}

@article{peters_characterizations_1978,
	title = {Characterizations of {Linear} {Sufficient} {Statistics}},
	volume = {40},
	issn = {0581-572X},
	abstract = {We develop necessary and sufficient conditions that a surjective bounded linear operator T from a linear space X to a linear space Y be a sufficient statistic for a dominated family of probability measures defined on the Borel sets of X. We give applications of these results that characterize linear sufficient statistics for families of the exponential type, including as special cases the Wishart and multivariate normal distributions.},
	number = {3},
	urldate = {2016-11-10},
	journal = {Sankhya Ser. A},
	author = {Peters, B. Charles and Redner, Richard and Decell, Henry P.},
	year = {1978},
	pages = {303--309}
}

@article{zeng_optimizing_2015,
	title = {Optimizing wastewater pumping system with data-driven models and a greedy electromagnetism-like algorithm},
	volume = {30},
	issn = {1436-3240, 1436-3259},
	doi = {10.1007/s00477-015-1115-4},
	abstract = {Optimizing a pumping system in the wastewater treatment process by improving its operational schedules is presented. The energy consumption and outflow rate of the pumping system are modeled by a data-driven approach. A mixed-integer nonlinear programming (MINLP) model containing data-driven components and pump operational constraints is developed to minimize the energy consumption of the pumping system while maintaining the required pumping workload. A greedy electromagnetism-like (GEM) algorithm is designed to solve the MINLP model for optimized operational schedules and pump speeds. Three computational cases are studied to demonstrate the effectiveness of the proposed data-driven modeling and GEM algorithm. The computational results show that significant energy saving can be obtained.},
	language = {en},
	number = {4},
	urldate = {2016-10-17},
	journal = {Stoch. Environ. Res. Risk Assess.},
	author = {Zeng, Yaohui and Zhang, Zijun and Kusiak, Andrew and Tang, Fan and Wei, Xiupeng},
	month = jun,
	year = {2015},
	pages = {1263--1275},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\HU9KTJFZ\\Zeng et al. - 2015 - Optimizing wastewater pumping system with data-dri.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\7EN8WGDW\\s00477-015-1115-4.html:text/html}
}

@article{saul_think_2003,
	title = {Think globally, fit locally: unsupervised learning of low dimensional manifolds},
	volume = {4},
	issn = {ISSN 1533-7928},
	shorttitle = {Think {Globally}, {Fit} {Locally}},
	number = {Jun},
	urldate = {2016-10-17},
	journal = {J. Mach. Learn. Res.},
	author = {Saul, Lawrence K. and Roweis, Sam T.},
	year = {2003},
	pages = {119--155},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\USW899CF\\Saul and Roweis - 2003 - Think Globally, Fit Locally Unsupervised Learning.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\P35B4X4Q\\saul03a.html:text/html}
}

@book{haykin_neural_1999,
	address = {Upper Saddle River, N.J. : London},
	title = {Neural {Networks}: {A} {Comprehensive} {Foundation}},
	isbn = {978-0-13-273350-2},
	shorttitle = {Neural networks},
	urldate = {2016-10-14},
	publisher = {Prentice Hall ; Prentice-Hall International},
	author = {Haykin, Simon S.},
	year = {1999},
	keywords = {Neural networks (Computer science)},
	annote = {Bibliography: p. 796-836},
	annote = {Includes index.},
	annote = {Previous ed.: London : Maxwell Macmillan International, 1994},
	file = {Hathi Trust Record:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\U7UW4F7M\\003982561.html:text/html}
}

@article{tenenbaum_global_2000,
	title = {A global geometric framework for nonlinear dimensionality reduction},
	volume = {290},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.290.5500.2319},
	abstract = {Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs—30,000 auditory nerve fibers or 106 optic nerve fibers—a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.},
	language = {en},
	number = {5500},
	urldate = {2016-10-17},
	journal = {Science},
	author = {Tenenbaum, Joshua B. and Silva, Vin de and Langford, John C.},
	month = dec,
	year = {2000},
	pmid = {11125149},
	pages = {2319--2323},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\EPRDMDZE\\Tenenbaum et al. - 2000 - A Global Geometric Framework for Nonlinear Dimensi.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\P3DJX4Q5\\2319.html:text/html}
}

@article{gikas_role_2009,
	title = {The role of satellite and decentralized strategies in water resources management},
	volume = {90},
	issn = {0301-4797},
	doi = {10.1016/j.jenvman.2007.08.016},
	abstract = {Existing and projected water shortages and related factors have helped focus attention on the need for water reuse. With recent technological advances in wastewater treatment, it is now possible to produce reclaimed water of any quality. Thus, the use of reclaimed water will depend on the reuse opportunities and the cost of the required infrastructure. Historically, centralized wastewater treatment facilities have served the needs of organized societies since the mid 1800s. However, as there are limited options for expansion of most existing centralized facilities, the use of satellite and decentralized wastewater management systems offers significant advantages including being close both to the source of wastewater generation and to potential water reuse applications. The comparative advantages of satellite and decentralized wastewater management systems for a number of water reuse applications are presented and discussed in this paper. Selected case studies are presented to demonstrate the utility of satellite and decentralized wastewater management. Specific issues associated with the application of such systems in existing and in new developments are examined and discussed.},
	number = {1},
	urldate = {2016-10-14},
	journal = {J. Environ. Manage.},
	author = {Gikas, Petros and Tchobanoglous, George},
	month = jan,
	year = {2009},
	keywords = {Decentralized system, Recycling, Satellite system, Wastewater, Water management, Water reuse},
	pages = {144--152},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\TE2SDHUX\\Gikas and Tchobanoglous - 2009 - The role of satellite and decentralized strategies.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\QD8XMRQT\\S0301479707003131.html:text/html}
}

@article{nguyen_fault_2010,
	title = {Fault detection based on {Kernel} {Principal} {Component} {Analysis}},
	volume = {32},
	issn = {0141-0296},
	doi = {10.1016/j.engstruct.2010.08.012},
	abstract = {In the field of structural health monitoring or machine condition monitoring, the activation of nonlinear dynamic behavior may render the procedure of damage or fault detection more difficult. Principal Component Analysis (PCA) is known as a popular method for diagnosis but as it is basically a linear method, it may pass over some useful nonlinear features of the system behavior. One possible extension of PCA is Kernel PCA (KPCA), owing to the use of nonlinear kernel functions that allow introduction of nonlinear dependences between variables. The objective of this paper is to address the problem of fault detection (in terms of nonlinear activation) in mechanical systems using a KPCA-based method. The detection is achieved by comparing the subspaces between the reference and a current state of the system through the concept of subspace angle. It is shown in this work that the exploitation of the measurements in the form of block Hankel matrices can effectively improve the detection results. The method is illustrated on an experimental example consisting of a beam with a geometric nonlinearity.},
	number = {11},
	urldate = {2016-10-14},
	journal = {Eng. Struct.},
	author = {Nguyen, Viet Ha and Golinval, Jean-Claude},
	month = nov,
	year = {2010},
	keywords = {Detection, KPCA, Nonlinearity, PCA, Subspace},
	pages = {3683--3691},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\XZBQBATM\\Nguyen and Golinval - 2010 - Fault detection based on Kernel Principal Componen.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\4KI3D2T5\\S0141029610003019.html:text/html}
}

@article{russell_fault_2000,
	title = {Fault detection in industrial processes using canonical variate analysis and dynamic principal component analysis},
	volume = {51},
	issn = {0169-7439},
	doi = {10.1016/S0169-7439(00)00058-7},
	abstract = {Principal component analysis (PCA) is a well-known data dimensionality technique that has been used to detect faults during the operation of industrial processes. Dynamic principal component analysis (DPCA) and canonical variate analysis (CVA) are data dimensionality techniques which take into account serial correlations, but their effectiveness in detecting faults in industrial processes has not been extensively tested. In this paper, score/state and residual space PCA, DPCA, and CVA are applied to the Tennessee Eastman process simulator, which was designed to simulate a wide variety of faults occurring in a chemical plant based on a facility at Eastman Chemical. This appears to be the first application of residual space CVA statistics for detecting faults in a large-scale process.

Statistics quantifying variations in the residual space were usually more sensitive but less robust to the faults than the statistics quantifying the variations in the score or state space. The statistics exhibiting a small missed detection rate tended to exhibit small detection delays and vice versa. A residual-based CVA statistic proposed in this paper gave the best overall sensitivity and promptness, but the initially proposed threshold for the statistic lacked robustness. This motivated increasing the threshold to achieve a specified missed detection rate.},
	number = {1},
	urldate = {2016-10-17},
	journal = {Chemometr. Intell. Lab.},
	author = {Russell, Evan L. and Chiang, Leo H. and Braatz, Richard D.},
	month = may,
	year = {2000},
	keywords = {Canonical variate analysis, Chemometrics methods, Dynamic Principal Component Analysis, Fault detection, Multivariate statistics, Principal Component Analysis, Process monitoring, Tennessee Eastman process},
	pages = {81--93},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\X67MP3B6\\Russell et al. - 2000 - Fault detection in industrial processes using cano.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\38HC6H3H\\S0169743900000587.html:text/html}
}

@article{nikiforov_energy_2007,
	title = {The energy of graphs and matrices},
	volume = {326},
	issn = {0022-247X},
	doi = {10.1016/j.jmaa.2006.03.072},
	abstract = {Given a complex m × n matrix A, we index its singular values as σ 1 ( A ) ⩾ σ 2 ( A ) ⩾ ⋯ and call the value E ( A ) = σ 1 ( A ) + σ 2 ( A ) + ⋯ the energy of A, thereby extending the concept of graph energy, introduced by Gutman. Let 2 ⩽ m ⩽ n , A be an m × n nonnegative matrix with maximum entry α, and ‖ A ‖ 1 ⩾ n α . Extending previous results of Koolen and Moulton for graphs, we prove that E ( A ) ⩽ ‖ A ‖ 1 m n + ( m − 1 ) ( ‖ A ‖ 2 2 − ‖ A ‖ 1 2 m n ) ⩽ α n ( m + m ) 2 . Furthermore, if A is any nonconstant matrix, then E ( A ) ⩾ σ 1 ( A ) + ‖ A ‖ 2 2 − σ 1 2 ( A ) σ 2 ( A ) . 

Finally, we note that Wigner's semicircle law implies that E ( G ) = ( 4 3 π + o ( 1 ) ) n 3 / 2 for almost all graphs G.},
	number = {2},
	urldate = {2017-01-21},
	journal = {Journal of Mathematical Analysis and Applications},
	author = {Nikiforov, Vladimir},
	month = feb,
	year = {2007},
	keywords = {Graph eigenvalues, Graph energy, Matrix energy, Singular values, Wigner's semicircle law},
	pages = {1472--1475},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\W6JPK4DV\\Nikiforov - 2007 - The energy of graphs and matrices.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\FEJ8RFFH\\S0022247X06003258.html:text/html}
}

@article{schott_dimensionality_1993,
	title = {Dimensionality reduction in quadratic discriminant analysis},
	volume = {16},
	issn = {0167-9473},
	doi = {10.1016/0167-9473(93)90111-6},
	abstract = {One common objective of many multivariate techniques is to achieve a reduction in dimensionality while at the same time retain most of the relevant information contained in the original data set. This reduction not only provides a parsimonious description of the data but, in many cases, also increases the reliability of subsequent analyses of the data. In this paper we consider the problem of determining the minimum dimension necessary for quadratic discrimination in normal populations with heterogeneous covariance matrices. Some asymptotic chi-squared tests are obtained. Simulations are used to investigate the adequacy of the chi-squared approximations and to compare the misclassification probabilities of reduced-dimension quadratic discrimination with full-dimension quadratic discrimination.},
	number = {2},
	urldate = {2016-09-28},
	journal = {Comput. Stat. Data An.},
	author = {Schott, James R.},
	month = aug,
	year = {1993},
	keywords = {Eigenprojection, Heterogeneous covariance matrices, Misclassification probability},
	pages = {161--174},
	file = {ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\BPUP52VS\\0167947393901116.html:text/html}
}

@book{venables_modern_1999,
	address = {New York},
	edition = {3rd ed},
	series = {Statistics and computing},
	title = {Modern applied statistics with {S}-{PLUS}},
	isbn = {978-0-387-98825-2},
	publisher = {Springer},
	author = {Venables, W. N. and Ripley, Brian D.},
	year = {1999},
	keywords = {Data processing, Mathematical statistics, S-Plus, Statistics}
}

@article{roweis_nonlinear_2000,
	title = {Nonlinear dimensionality reduction by locally linear embedding},
	volume = {290},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.290.5500.2323},
	abstract = {Many areas of science depend on exploratory data analysis and visualization. The need to analyze large amounts of multivariate data raises the fundamental problem of dimensionality reduction: how to discover compact representations of high-dimensional data. Here, we introduce locally linear embedding (LLE), an unsupervised learning algorithm that computes low-dimensional, neighborhood-preserving embeddings of high-dimensional inputs. Unlike clustering methods for local dimensionality reduction, LLE maps its inputs into a single global coordinate system of lower dimensionality, and its optimizations do not involve local minima. By exploiting the local symmetries of linear reconstructions, LLE is able to learn the global structure of nonlinear manifolds, such as those generated by images of faces or documents of text.},
	language = {en},
	number = {5500},
	urldate = {2016-10-17},
	journal = {Science},
	author = {Roweis, Sam T. and Saul, Lawrence K.},
	month = dec,
	year = {2000},
	pmid = {11125150},
	pages = {2323--2326},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\Z2QWW9U2\\Roweis and Saul - 2000 - Nonlinear Dimensionality Reduction by Locally Line.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\RS3EC2KD\\2323.html:text/html}
}

@book{cristianini_introduction_2000,
	address = {Cambridge ; New York},
	title = {An {Introduction} to {Support} {Vector} {Machines}: {And} {Other} {Kernel}-{Based} {Learning} {Methods}},
	isbn = {978-0-521-78019-3},
	shorttitle = {An introduction to support vector machines},
	publisher = {Cambridge University Press},
	author = {Cristianini, Nello and Shawe-Taylor, John},
	year = {2000},
	keywords = {Algorithms, Kernel functions, Machine learning}
}

@article{jackson_control_1979,
	title = {Control procedures for residuals associated with principal component analysis},
	volume = {21},
	issn = {0040-1706},
	doi = {10.2307/1267757},
	abstract = {This paper is concerned with the treatment of residuals associated with principal component analysis. These residuals are the difference between the original observations and the predictions of them using less than a full set of principal components. Specifically, procedures are proposed for testing the residuals associated with a single observation vector and for an overall test for a group of observations. In this development, it is assumed that the underlying covariance matrix is known; this is reasonable for many quality control applications where the proposed procedures may be quite useful in detecting outliers in the data. A numerical example is included.},
	number = {3},
	urldate = {2016-10-14},
	journal = {Technometrics},
	author = {Jackson, J. Edward and Mudholkar, Govind S.},
	year = {1979},
	pages = {341--349}
}

@article{downs_plant-wide_1993,
	series = {Industrial challenge problems in process control},
	title = {A plant-wide industrial process control problem},
	volume = {17},
	issn = {0098-1354},
	doi = {10.1016/0098-1354(93)80018-I},
	abstract = {This paper describes a model of an industrial chemical process for the purpose of developing, studying and evaluating process control technology. This process is well suited for a wide variety of studies including both plant-wide control and multivariable control problems. It consists of a reactor/ separator/recycle arrangement involving two simultaneous gas—liquid exothermic reactions of the following form: A(g) + C(g) + D(g) → G(liq), Product 1, A(g) + C(g) + E(g) → H(liq), Product 2. Two additional byproduct reactions also occur. The process has 12 valves available for manipulation and 41 measurements available for monitoring or control. The process equipment, operating objectives, process control objectives and process disturbances are described. A set of FORTRAN subroutines which simulate the process are available upon request. The chemical process model presented here is a challenging problem for a wide variety of process control technology studies. Even though this process has only a few unit operations, it is much more complex than it appears on first examination. We hope that this problem will be useful in the development of the process control field. We are also interested in hearing about applications of the problem.},
	number = {3},
	urldate = {2016-10-14},
	journal = {Comput. Chem. Eng.},
	author = {Downs, J. J. and Vogel, E. F.},
	month = mar,
	year = {1993},
	pages = {245--255},
	file = {ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\8SWDBKET\\009813549380018I.html:text/html}
}

@phdthesis{kayo_locally_2006,
	title = {Locally linear embedding algorithm : extensions and applications},
	shorttitle = {Locally linear embedding algorithm},
	language = {eng},
	author = {Kayo, Olga},
	year = {2006},
	file = {:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\CMI6K9U3\\isbn951-42-8041-5.html:text/html}
}

@article{hart_automated_1996,
	title = {Some automated methods of smoothing time-dependent data},
	volume = {6},
	issn = {1048-5252},
	doi = {10.1080/10485259608832667},
	abstract = {Nonparametric function estimation based upon time-dependent data is a challenging problem to both the data analyst and the theoretician. This paper serves as an introduction to the problem and discusses some of the approaches that have been proposed for smoothing autocorrelated data. A principal theme will be accounting for correlation in the data driven choice of a function estimator's smoothing parameter. Data-driven smoothing is considered in various settings including probability density estimation, repeated measures data, and time series trend estimation. Both applications and theoretical issues are addressed, and some open problems will be discussed.},
	number = {2-3},
	urldate = {2016-10-14},
	journal = {J. Nonparametr. Stat.},
	author = {Hart, Jeffrey D.},
	month = jan,
	year = {1996},
	keywords = {autoregression, block wise cross-validation, cross-validation, Kernel estimators, mean integrated squared error, plug-in rules, prequential analysis, time series cross-validation, transition densities},
	pages = {115--142},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\2BWHBJCC\\10485259608832667.html:text/html}
}

@article{cook_theory_2001,
	title = {Theory \& methods: {Special} {Invited} {Paper}: {Dimension} reduction and visualization in discriminant analysis},
	volume = {43},
	copyright = {Australian Statistical Publishing Association Inc 2001},
	issn = {1467-842X},
	shorttitle = {Theory \& {Methods}},
	doi = {10.1111/1467-842X.00164},
	abstract = {This paper discusses visualization methods for discriminant analysis. It does not address numerical methods for classification per se, but rather focuses on graphical methods that can be viewed as pre-processors, aiding the analyst's understanding of the data and the choice of a final classifier. The methods are adaptations of recent results in dimension reduction for regression, including sliced inverse regression and sliced average variance estimation. A permutation test is suggested as a means of determining dimension, and examples are given throughout the discussion.},
	language = {en},
	number = {2},
	urldate = {2016-06-22},
	journal = {Aust. N.Z. J. Stat.},
	author = {Cook, R. Dennis and Yin, Xiangrong},
	month = jun,
	year = {2001},
	keywords = {central subspaces, dimension reduction, regression, regression graphics, sliced average variance estimation (SAVE)., sliced inverse regression (SIR)},
	pages = {147--199},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\ZR8AI58W\\Cook and Yin - 2001 - Theory & Methods Special Invited Paper Dimension.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\GFF7FGU3\\abstract.html:text/html}
}

@article{nguyen_multi-class_2002,
	title = {Multi-class cancer classification via partial least squares with gene expression profiles},
	volume = {18},
	issn = {1367-4803},
	abstract = {MOTIVATION: Discrimination between two classes such as normal and cancer samples and between two types of cancers based on gene expression profiles is an important problem which has practical implications as well as the potential to further our understanding of gene expression of various cancer cells. Classification or discrimination of more than two groups or classes (multi-class) is also needed. The need for multi-class discrimination methodologies is apparent in many microarray experiments where various cancer types are considered simultaneously.
RESULTS: Thus, in this paper we present the extension to the classification methodology proposed earlier Nguyen and Rocke (2002b; Bioinformatics, 18, 39-50) to classify cancer samples from multiple classes. The methodologies proposed in this paper are applied to four gene expression data sets with multiple classes: (a) a hereditary breast cancer data set with (1) BRCA1-mutation, (2) BRCA2-mutation and (3) sporadic breast cancer samples, (b) an acute leukemia data set with (1) acute myeloid leukemia (AML), (2) T-cell acute lymphoblastic leukemia (T-ALL) and (3) B-cell acute lymphoblastic leukemia (B-ALL) samples, (c) a lymphoma data set with (1) diffuse large B-cell lymphoma (DLBCL), (2) B-cell chronic lymphocytic leukemia (BCLL) and (3) follicular lymphoma (FL) samples, and (d) the NCI60 data set with cell lines derived from cancers of various sites of origin. In addition, we evaluated the classification algorithms and examined the variability of the error rates using simulations based on randomization of the real data sets. We note that there are other methods for addressing multi-class prediction recently and our approach is along the line of Nguyen and Rocke (2002b; Bioinformatics, 18, 39-50).
CONTACT: dnguyen@stat.tamu.edu; dmrocke@ucdavis.edu},
	language = {eng},
	number = {9},
	journal = {Bioinformatics},
	author = {Nguyen, Danh V. and Rocke, David M.},
	month = sep,
	year = {2002},
	pmid = {12217913},
	keywords = {Algorithms, Breast Neoplasms, Databases, Nucleic Acid, Discriminant Analysis, Gene Expression Profiling, Gene Expression Regulation, Neoplastic, Humans, Least-Squares Analysis, Leukemia, Lymphoma, Models, Genetic, Models, Statistical, Neoplasms, Oligonucleotide Array Sequence Analysis, Principal Component Analysis, Reproducibility of Results, Sensitivity and Specificity, Sequence Analysis, DNA, Tumor Cells, Cultured},
	pages = {1216--1226}
}

@article{mahanta_heteroscedastic_2012,
	title = {Heteroscedastic linear feature extraction based on sufficiency conditions},
	volume = {45},
	issn = {0031-3203},
	doi = {10.1016/j.patcog.2011.07.024},
	abstract = {Classification of high-dimensional data typically requires extraction of discriminant features. This paper proposes a linear feature extractor, called whitened linear sufficient statistic (WLSS),...},
	number = {2},
	urldate = {2016-06-22},
	journal = {Pattern Recogn.},
	author = {Mahanta, Mohammad Shahin and Aghaei, Amirhossein S. and Plataniotis, Konstantinos N. and Pasupathy, Subbarayan},
	month = feb,
	year = {2012},
	pages = {821--830},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\8F5ICU8P\\Mahanta et al. - 2012 - Heteroscedastic linear feature extraction based on.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\H2WWHRC2\\220601625_Heteroscedastic_linear_feature_extraction_based_on_sufficiency_conditions.html:text/html}
}

@article{zhang_improved_2013,
	title = {Improved {Locally} {Linear} {Embedding} based method for nonlinear system fault detection},
	volume = {5},
	copyright = {中国科学院},
	issn = {2005-8039},
	abstract = {In order to detect faults of nonlinear systems, an approach based on improved Locally Linear Embedding (LLE) was proposed. Firstly, the raw data was projected to lower dimensional space by LLE. In this step, tangent space distance was introduced to LLE and certain enhancement had also been made to intrinsic dimension estimation to make the approach more efficient and robust. Secondly, the inner class distance of data was calculated as an index of fault detection. To demonstrate the effectiveness of the improved LLE method, it is applied to Tennessee Eastman (TE) process and compared with kernel principle component analysis (KPCA) method. By simulation analysis, the false negative rate of the proposed approach achieves 4.498\% in average, which is much better than 77.53\% of KPCA, certifying the effectiveness of the approach to nonlinear fault detection.},
	number = {1},
	urldate = {2016-10-17},
	journal = {Chi. Acad. Sci. Int. J. Adv. Comp. Tech.},
	author = {Zhang, W and Liu, X Y and Qi, R L and Jiang, Y},
	year = {2013},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\WPKKFABG\\623001.html:text/html}
}

@article{khediri_variable_2011,
	title = {Variable window adaptive {Kernel} {Principal} {Component} {Analysis} for nonlinear nonstationary process monitoring},
	volume = {61},
	issn = {0360-8352},
	doi = {10.1016/j.cie.2011.02.014},
	abstract = {On-line control of nonlinear nonstationary processes using multivariate statistical methods has recently prompt a lot of interest due to its industrial practical importance. Indeed basic process control methods do not allow monitoring of such processes. For this purpose this study proposes a variable window real-time monitoring system based on a fast block adaptive Kernel Principal Component Analysis scheme. While previous adaptive KPCA models allow only handling of one observation at a time, in this study we propose a way to fast update or downdate the KPCA model when a block of data is provided and not only one observation. Using a variable window size procedure to determine the model size and adaptive chart parameters, this model is applied to monitor two simulated benchmark processes. A comparison of performances of the adopted control strategy with various Principal Component Analysis (PCA) control models shows that the derived strategy is robust and yields better detection abilities of disturbances.},
	number = {3},
	urldate = {2016-10-14},
	journal = {Comput. Ind. Eng.},
	author = {Khediri, Issam Ben and Limam, Mohamed and Weihs, Claus},
	month = oct,
	year = {2011},
	keywords = {Block adaptive Kernel Principal Component Analysis, Multivariate Statistical Process Control, Variable window control chart},
	pages = {437--446},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\CKPZKV96\\Khediri et al. - 2011 - Variable window adaptive Kernel Principal Componen.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\BP9QF4X5\\S0360835211000696.html:text/html}
}

@article{liu_moving_2009,
	series = {Chimiometrie 2007, {Lyon}, {France}, 29-30 {November} 2007},
	title = {Moving window kernel {PCA} for adaptive monitoring of nonlinear processes},
	volume = {96},
	issn = {0169-7439},
	doi = {10.1016/j.chemolab.2009.01.002},
	abstract = {This paper discusses the monitoring of complex nonlinear and time-varying processes. Kernel principal component analysis (KPCA) has gained significant attention as a monitoring tool for nonlinear systems in recent years but relies on a fixed model that cannot be employed for time-varying systems. The contribution of this article is the development of a numerically efficient and memory saving moving window KPCA (MWKPCA) monitoring approach. The proposed technique incorporates an up- and downdating procedure to adapt (i) the data mean and covariance matrix in the feature space and (ii) approximates the eigenvalues and eigenvectors of the Gram matrix. The article shows that the proposed MWKPCA algorithm has a computation complexity of O(N2), whilst batch techniques, e.g. the Lanczos method, are of O(N3). Including the adaptation of the number of retained components and an l-step ahead application of the MWKPCA monitoring model, the paper finally demonstrates the utility of the proposed technique using a simulated nonlinear time-varying system and recorded data from an industrial distillation column.},
	number = {2},
	urldate = {2016-10-14},
	journal = {Chemometr. Intell. Lab.},
	author = {Liu, Xueqin and Kruger, Uwe and Littler, Tim and Xie, Lei and Wang, Shuqing},
	month = apr,
	year = {2009},
	keywords = {Adaptive, Kernel PCA, Moving window, Multivariate Statistical Process Control, Nonlinear process, Numerically efficient},
	pages = {132--143},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\JD7E5TUN\\Liu et al. - 2009 - Moving window kernel PCA for adaptive monitoring o.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\E76IG7VI\\S0169743909000033.html:text/html}
}

@book{sheather_modern_2009,
	address = {New York, NY},
	series = {Springer {Texts} in {Statistics}},
	title = {A {Modern} {Approach} to {Regression} with {R}},
	isbn = {978-0-387-09607-0 978-0-387-09608-7},
	urldate = {2016-10-17},
	publisher = {Springer New York},
	author = {Sheather, Simon},
	editor = {Casella, George and Fienberg, Stephen and Olkin, Ingram},
	year = {2009}
}

@inproceedings{ham_kernel_2004,
	address = {New York, NY, USA},
	series = {{ICML} '04},
	title = {A kernel view of the dimensionality reduction of manifolds},
	isbn = {978-1-58113-838-2},
	doi = {10.1145/1015330.1015417},
	abstract = {We interpret several well-known algorithms for dimensionality reduction of manifolds as kernel methods. Isomap, graph Laplacian eigenmap, and locally linear embedding (LLE) all utilize local neighborhood information to construct a global embedding of the manifold. We show how all three algorithms can be described as kernel PCA on specially constructed Gram matrices, and illustrate the similarities and differences between the algorithms with representative examples.},
	urldate = {2016-10-14},
	booktitle = {Proceedings of the {Twenty}-first {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Ham, Jihun and Lee, Daniel D. and Mika, Sebastian and Schölkopf, Bernhard},
	year = {2004},
	pages = {47--},
	file = {ACM Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\4EPC8D64\\Ham et al. - 2004 - A Kernel View of the Dimensionality Reduction of M.pdf:application/pdf}
}

@article{rato_defining_2013,
	title = {Defining the structure of {DPCA} models and its impact on process monitoring and prediction activities},
	volume = {125},
	issn = {0169-7439},
	doi = {10.1016/j.chemolab.2013.03.009},
	abstract = {Dynamic Principal Component Analysis (DPCA) is an extension of Principal Component Analysis (PCA), developed in order to add the ability to capture the autocorrelative behavior of processes, to the existent and well-known PCA capability for modeling cross-correlation between variables. The simultaneous modeling of the dependencies along the “variable” and “time” modes, allows for a more compact and rigorous description of the normal behavior of processes, laying the ground for the development of, for instance, improved Statistical Process Monitoring (SPM) methodologies, able to robustly detect finer deviations from normal operation conditions. A key point in the application of DPCA is the definition of its structure, namely the selection of the number of time-shifted replicates for each variable to include, and the number of components to retain in the final model. In order to address the first of these two fundamental design aspects of DPCA, and arguably the most complex one, we propose two new lag selection methods.The first method estimates a single lag structure for all variables, whereas the second one refines this procedure, providing the specific number of lags to be used for each individual variable. The application of these two proposed methodologies to several case studies led to a more rigorous estimation of the number of lags really involved in the dynamical mechanisms of the processes under analysis. This feature can be explored for implementing improved system identification, process monitoring and process control tasks that rely upon a DPCA modeling framework.},
	urldate = {2016-10-14},
	journal = {Chemometr. Intell. Lab.},
	author = {Rato, Tiago J. and Reis, Marco S.},
	month = jun,
	year = {2013},
	keywords = {Dynamic principal component analysis (DPCA), Lag selection, Multivariate statistical process control (MSPC), System identification},
	pages = {74--86},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\9IUFAXGR\\Rato and Reis - 2013 - Defining the structure of DPCA models and its impa.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\EFZZEAVJ\\S016974391300049X.html:text/html}
}

@incollection{zheng_fault_2013,
	title = {Fault {Diagnosis} of {Wet} {Flue} {Gas} {Desulphurization} {System} {Based} on {KPCA}},
	copyright = {©2013 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-37269-8 978-3-642-37270-4},
	abstract = {Fault detection and diagnosis for sensor are necessary, which affect the performance of the thermal power plant of wet flue gas desulphurization system seriously. A fault diagnosis method using kernel principal component analysis (KPCA) is proposed to affectively capture the nonlinear relationship of the process variables, which computes principal component in high dimensional feature space by means of integral operators and nonlinear kernel functions. The faults are detected by calculating the statistics of the square prediction error (SPE) and identified by calculating the change diagram of contribution percentage of Hostelling T2T2 \{T{\textasciicircum}2\} . At last, employing the actual data from wet flue gas desulphurization system of Huaneng Fuzhou power plant, it’s proved effectively to detect and identify four kinds of faults, which is the complete invalidation fault, fixed bias fault, drift bias fault and precision degradation fault. The result shows the KPCA method has a good performance in fault detection and diagnosis.},
	language = {en},
	urldate = {2016-10-17},
	booktitle = {The 19th {International} {Conference} on {Industrial} {Engineering} and {Engineering} {Management}},
	publisher = {Springer Berlin Heidelberg},
	author = {Zheng, Yu-ping and Zhang, Li-ping},
	editor = {Qi, Ershi and Shen, Jiang and Dou, Runliang},
	year = {2013},
	note = {DOI: 10.1007/978-3-642-37270-4\_27},
	keywords = {Fault detect and diagnosis, Gas desulphurization, Innovation/Technology Management, KPCA, Wet flue sensors},
	pages = {279--288},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\MHDS2IP8\\978-3-642-37270-4_27.html:text/html}
}

@unpublished{watrous_theory_2011,
	title = {Theory of {Quantum} {Information}},
	url = {https://cs.uwaterloo.ca/~watrous/CS766/LectureNotes/02.pdf},
	abstract = {The lecture notes of Prof. Watrous},
	urldate = {2017-01-21},
	author = {Watrous, John},
	year = {2011}
}

@article{scholkopf_nonlinear_1998,
	title = {Nonlinear component analysis as a kernel eigenvalue problem},
	volume = {10},
	issn = {0899-7667},
	doi = {10.1162/089976698300017467},
	abstract = {A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear map—for instance, the space of all possible five-pixel products in 16 × 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.},
	number = {5},
	urldate = {2016-10-17},
	journal = {Neural Comput.},
	author = {Scholkopf, Bernhard and Smola, Alexander and Muller, Klaus-Robert},
	month = jul,
	year = {1998},
	pages = {1299--1319},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\2Z27JJC2\\089976698300017467.html:text/html}
}

@article{chen_application_2000,
	title = {The application of principal component analysis and kernel density estimation to enhance process monitoring},
	volume = {8},
	issn = {0967-0661},
	doi = {10.1016/S0967-0661(99)00191-4},
	abstract = {This paper discusses the application of kernel density estimation (KDE) and principal component analysis (PCA) to provide enhanced monitoring of multivariate processes. Different KDE algorithms are studied and assessed in depth in the context of practical applications so that one bandwidth selection algorithm is recommended for process monitoring. The results of the case studies clearly demonstrate the power and advantages of the KDE approach over parametric density estimation which is still widely used. Statistical summary charts are suggested to raise early warning of faults and locate the physical variables which are the prime indicators of the faults.},
	number = {5},
	urldate = {2016-10-14},
	journal = {Control Eng. Pract.},
	author = {Chen, Q. and Wynne, R. J. and Goulding, P. and Sandoz, D.},
	month = may,
	year = {2000},
	keywords = {Kernel density estimation, Multivariate processes, Principal Component Analysis, Process monitoring},
	pages = {531--543},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\ZDGUZE5T\\Chen et al. - 2000 - The application of principal component analysis an.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\2FCI4DM6\\S0967066199001914.html:text/html}
}

@inproceedings{kumar_generalization_1996,
	title = {A generalization of linear discriminant analysis in maximum likelihood framework},
	abstract = {The Fisher--Rao linear discriminant analysis (LDA) is a valuable tool for multi-class classification and data reduction. We investigate LDA within the maximum likelihood framework and propose a general formulation to handle heteroscedasticity. Small size numerical experiments with randomly generated data verify the validity of our formulation. I. Introduction  Linear discriminant analysis (LDA) is a mathematical tool widely used for dimensionality reduction and multi-class classification [1], [2], [3]. Our interest in LDA [4] stems from our desire to use auditory features in speech recognition and from the encouraging results obtained by Brown [5]. However, inconsistent modeling assumptions between LDA, and the models used for recognition yield final systems with non-optimum performance. LDA can be derived as a maximum likelihood method for normal populations with different means, and common co-variance matrices [6]. Hastie [7] has further generalized this approach to the case where cl...},
	author = {Kumar, Nagendra and Andreou, Andreas G. and Andreou, Nagendra Kumar Andreas G.},
	year = {1996},
	file = {Citeseer - Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\ZFI863ED\\Kumar et al. - 1996 - A Generalization Of Linear Discriminant Analysis I.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\TTXE5AZ5\\summary.html:text/html}
}

@article{sigillito_classification_1989,
	title = {Classification of radar returns from the ionosphere using neural networks},
	volume = {vol. 10},
	journal = {J. Hopkins Apl. Tech. D.},
	author = {Sigillito, V. G. and Wing, S. P. and Hutton, L. V. and Baker, K. B.},
	year = {1989},
	note = {in},
	pages = {262--266}
}

@inproceedings{bengio_out--sample_2003,
	title = {Out-of-sample extensions for {LLE}, isomap, {MDS}, eigenmaps, and spectral clustering},
	abstract = {Several unsupervised learning algorithms based on an eigendecomposition provide  either an embedding or a clustering only for given training points, with no  straightforward extension for out-of-sample examples short of recomputing eigenvectors.},
	booktitle = {In {Advances} in {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Bengio, Yoshua and Paiement, Jean-Francois and Vincent, Pascal},
	year = {2003},
	pages = {177--184},
	file = {Citeseer - Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\EJSMM685\\Bengio et al. - 2003 - Out-of-Sample Extensions for LLE, Isomap, MDS, Eig.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\2V259FV8\\summary.html:text/html}
}

@article{hastie_forward_2007,
	title = {Forward stagewise regression and the monotone lasso},
	volume = {1},
	issn = {1935-7524},
	doi = {10.1214/07-EJS004},
	abstract = {We consider the least angle regression and forward stagewise algorithms for solving penalized least squares regression problems. In Efron, Hastie, Johnstone \& Tibshirani (2004) it is proved that the least angle regression algorithm, with a small modification, solves the lasso regression problem. Here we give an analogous result for incremental forward stagewise regression, showing that it solves a version of the lasso problem that enforces monotonicity. One consequence of this is as follows: while lasso makes optimal progress in terms of reducing the residual sum-of-squares per unit increase in L1-norm of the coefficient β, forward stage-wise is optimal per unit L1 arc-length traveled along the coefficient path. We also study a condition under which the coefficient paths of the lasso are monotone, and hence the different algorithms coincide. Finally, we compare the lasso and forward stagewise procedures in a simulation study involving a large number of correlated predictors.},
	language = {EN},
	urldate = {2017-01-27},
	journal = {Electron. J. Statist.},
	author = {Hastie, Trevor and Taylor, Jonathan and Tibshirani, Robert and Walther, Guenther},
	year = {2007},
	mrnumber = {MR2312144},
	zmnumber = {05274607},
	keywords = {lasso, regression, stagewise},
	pages = {1--29},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\WJWD7RUD\\1177687773.html:text/html}
}

@incollection{leverenz_4.03_2011,
	address = {Oxford},
	title = {4.03 - {Wastewater} {Reclamation} and {Reuse} {System} {A}2  - {Wilderer}, {Peter}},
	isbn = {978-0-444-53199-5},
	abstract = {Water reclamation and reuse provides a unique and viable opportunity to augment traditional water supplies. As a multi-disciplined and an important element of water resources development and management, water reuse can help to close the loop between water supply and wastewater disposal. Effective water reuse requires integration of water and reclaimed water supply functions. The successful development of this reliable water resource depends upon close examination and synthesis of elements from infrastructure and facilities planning, wastewater treatment plant siting, treatment process reliability, economic and financial analyses, public acceptance, and water utility management.

A key factor limiting the implementation of water reuse systems is often the cost of infrastructure needed for a conventional water reuse system, where the water reuse system consists generally of an upgraded secondary treatment process sited at an existing wastewater-treatment facility. It is often prohibitive logistically to return reclaimed water to urban areas where it could be used at maximum benefit to offset potable water supply consumption. The issues related to the return of reclaimed water to urban areas can be overcome, in part, using distributed water reuse systems such as satellite and decentralized configurations. In addition to a discussion on the alternative infrastructure approaches for water reuse, applications for reclaimed water, treatment technologies, and source control for upstream management of specific constituents are described briefly.},
	urldate = {2016-10-14},
	booktitle = {Treatise on {Water} {Science}},
	publisher = {Elsevier},
	author = {Leverenz, H. L. and Asano, T.},
	year = {2011},
	keywords = {Decentralized systems, Distributed systems, Graywater, Public health, Satellite systems, Source control, Treatment technology, Wastewater, Water infrastructure, Water quality, Water reclamation, Water reuse, Water supply},
	pages = {63--71},
	file = {ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\2HG74HFA\\B9780444531995000762.html:text/html}
}

@article{cheng_adaptive_2010,
	title = {Adaptive {Kernel} {Principal} {Component} {Analysis} ({KPCA}) for {Monitoring} {Small} {Disturbances} of {Nonlinear} {Processes}},
	volume = {49},
	issn = {0888-5885},
	url = {http://dx.doi.org/10.1021/ie900521b},
	doi = {10.1021/ie900521b},
	abstract = {The Tennessee Eastman (TE) process, created by Eastman Chemical Company, is a complex nonlinear process. Many previous studies focus on the detectability of monitoring a multivariate process by using TE process as an example. Principal component analysis (PCA) is a widely used dimension-reduction tool for monitoring multivariate linear process. Recently, the kernel principal component analysis (KPCA) has emerged as an effective method to tackling the problem of nonlinear data. Nevertheless, the conventional KPCA used the sum of squares of latest observations as the monitoring statistics and hence failed to detect small disturbance of the process. To enhance the detectability of the KPCA-based monitoring method, an adaptive KPCA-based monitoring statistic is proposed in this paper. The basic idea of the proposed method is first adopting the multivariate exponentially moving average to predict the process mean shifts and then combining the estimated mean shifts with the extracted components by KPCA to construct the adaptive monitoring statistic. The efficiency of the proposed monitoring scheme is implemented in a simulated nonlinear system and in the TE process. The experimental results indicate that the proposed method outperforms the traditional PCA and KPCA monitoring schemes.},
	number = {5},
	urldate = {2016-10-14},
	journal = {Ind. Eng. Chem. Res.},
	author = {Cheng, Chun-Yuan and Hsu, Chun-Chin and Chen, Mu-Chen},
	month = mar,
	year = {2010},
	pages = {2254--2262},
	file = {ACS Full Text PDF w/ Links:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\22TET9UP\\Cheng et al. - 2010 - Adaptive Kernel Principal Component Analysis (KPCA.pdf:application/pdf;ACS Full Text Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\2THG2PI5\\ie900521b.html:text/html}
}

@article{dong_batch_1996,
	title = {Batch tracking via nonlinear principal component analysis},
	volume = {42},
	issn = {1547-5905},
	doi = {10.1002/aic.690420810},
	abstract = {Batch processes are very important to the chemical and manufacturing industries. Techniques for monitoring these batch processes to ensure their safe operation and to produce consistently high-quality products are needed. Nomikos and MacGregor (1994) presented a multiway principal component analysis (MPCA) approach for monitoring batch processes, and test results show that the method is simple, powerful, and effective. MPCA, however, is a linear method, and most batch processes are nonlinear. Although data treatment techniques can remove some nonlinearity from the data, nonlinearity is still a problem when using MPCA for monitoring. In this article a nonlinear principal component analysis (NLPCA) method (Dong and McAvoy, 1993) is used for batch process monitoring. Results show that this method is excellent for this problem. Another interesting extension of this approach involves multistage batch process monitoring, which is illustrated through a detailed simulation study.},
	language = {en},
	number = {8},
	urldate = {2016-10-14},
	journal = {AIChE J.},
	author = {Dong, Dong and McAvoy, Thomas J.},
	month = aug,
	year = {1996},
	pages = {2199--2208},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\RGFWREAI\\Dong and McAvoy - 1996 - Batch tracking via nonlinear principal component a.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\KEPITGN2\\abstract.html:text/html}
}

@article{velilla_method_2008,
	title = {A method for dimension reduction in quadratic classification problems},
	volume = {17},
	issn = {1061-8600},
	abstract = {This article presents a dimension-reduction method in quadratic discriminant analysis (QDA). The procedure is inspired by the geometric relation that exists between the subspaces used in sliced inverse regression (SIR) and sliced average variance estimation (SAVE). A new set of directions is constructed to improve the properties of the directions associated with the eigenvectors of the matrices usually considered for dimension reduction in QDA. Illustrative examples of application with real and simulated data are discussed.},
	number = {3},
	urldate = {2016-06-22},
	journal = {J. Comput. Graph. Stat.},
	author = {Velilla, Santiago},
	year = {2008},
	pages = {572--589}
}

@article{cook_envelope_2010,
	title = {Envelope models for parsimonious and efficient multivariate linear regression},
	volume = {20},
	issn = {1017-0405},
	abstract = {We propose a new parsimonious version of the classical multivariate normal linear model, yielding a maximum likelihood estimator (MLE) that is asymptotically less variable than the MLE based on the usual model. Our approach is based on the construction of a link between the mean function and the covariance matrix, using the minimal reducing subspace of the latter that accommodates the former. This leads to a multivariate regression model that we call the envelope model, where the number of parameters is maximally reduced. The MLE from the envelope model can be substantially less variable than the usual MLE, especially when the mean function varies in directions that are orthogonal to the directions of maximum variation for the covariance matrix.},
	number = {3},
	urldate = {2016-09-27},
	journal = {Stat. Sinica},
	author = {Cook, R. Dennis and Li, Bing and Chiaromonte, Francesca},
	year = {2010},
	pages = {927--960}
}

@article{li_sliced_1991,
	title = {Sliced inverse regression for dimension reduction},
	volume = {86},
	issn = {0162-1459},
	doi = {10.2307/2290563},
	abstract = {Modern advances in computing power have greatly widened scientists' scope in gathering and investigating information from many variables, information which might have been ignored in the past. Yet to effectively scan a large pool of variables is not an easy task, although our ability to interact with data has been much enhanced by recent innovations in dynamic graphics. In this article, we propose a novel data-analytic tool, sliced inverse regression (SIR), for reducing the dimension of the input variable x without going through any parametric or nonparametric model-fitting process. This method explores the simplicity of the inverse view of regression; that is, instead of regressing the univariate output variable y against the multivariate x, we regress x against y. Forward regression and inverse regression are connected by a theorem that motivates this method. The theoretical properties of SIR are investigated under a model of the form, y = f(β1x, ..., βKx, ε), where the βk's are the unknown row vectors. This model looks like a nonlinear regression, except for the crucial difference that the functional form of f is completely unknown. For effectively reducing the dimension, we need only to estimate the space [effective dimension reduction (e.d.r.) space] generated by the βk's. This makes our goal different from the usual one in regression analysis, the estimation of all the regression coefficients. In fact, the βk's themselves are not identifiable without a specific structural form on f. Our main theorem shows that under a suitable condition, if the distribution of x has been standardized to have the zero mean and the identity covariance, the inverse regression curve, E(x ∣ y), will fall into the e.d.r. space. Hence a principal component analysis on the covariance matrix for the estimated inverse regression curve can be conducted to locate its main orientation, yielding our estimates for e.d.r. directions. Furthermore, we use a simple step function to estimate the inverse regression curve. No complicated smoothing is needed. SIR can be easily implemented on personal computers. By simulation, we demonstrate how SIR can effectively reduce the dimension of the input variable from, say, 10 to K = 2 for a data set with 400 observations. The spin-plot of y against the two projected variables obtained by SIR is found to mimic the spin-plot of y against the true directions very well. A chi-squared statistic is proposed to address the issue of whether or not a direction found by SIR is spurious.},
	number = {414},
	urldate = {2016-06-22},
	journal = {J. Am. Stat. Assoc.},
	author = {Li, Ker-Chau},
	year = {1991},
	pages = {316--327}
}

@article{fischer_distributionfree_1979,
	title = {On a distributionfree method in discriminant analysis},
	volume = {10},
	issn = {0323-3944},
	doi = {10.1080/02331887908801484},
	abstract = {Linear discriminant rules for two symmetrical distributions, which only need the first and second moments of these distributions, are presented. The rules are based on Zhezhel's idea using the most unfavourable probabilities of misclassification as an optimality criterion. Also a rule is considered which deals with distributions differing in a location and scale parameter.},
	number = {2},
	urldate = {2016-12-19},
	journal = {Statistics},
	author = {Fischer, K. and Thiele, Chr},
	month = jan,
	year = {1979},
	keywords = {BAYESian rule, Discriminant Analysis, minimax rule, most unfavourable probability of misclassification},
	pages = {281--289},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\NSQVEBGU\\02331887908801484.html:text/html}
}

@article{velilla_consistency_2005,
	title = {On the consistency properties of linear and quadratic discriminant analyses},
	volume = {96},
	issn = {0047-259X},
	doi = {10.1016/j.jmva.2004.10.009},
	abstract = {The limit behavior of the conditional probability of error of linear and quadratic discriminant analyses is studied under wide assumptions on the class conditional distributions. Results obtained may help to explain analytically the behavior in applications of linear and quadratic discrimination techniques.},
	number = {2},
	urldate = {2016-06-22},
	journal = {J. Multivariate Anal.},
	author = {Velilla, Santiago and Hernandez, Adolfo},
	month = oct,
	year = {2005},
	keywords = {Bayes error, Conditional probability of misclassification, Consistent sample discriminant rules, Inverse regression models, Plug-in sample discriminant rules},
	pages = {219--236},
	file = {ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\XNSPA7ZM\\S0047259X04002179.html:text/html}
}

@article{kruger_improved_2004,
	title = {Improved principal component monitoring of large-scale processes},
	volume = {14},
	issn = {0959-1524},
	doi = {10.1016/j.jprocont.2004.02.002},
	abstract = {In this work, the integration of ARMA filters into the multivariate statistical process control (MSPC) framework is presented to improve the monitoring of large-scale industrial processes. As demonstrated in the paper, such filters can remove auto-correlation from the monitored variables to avoid the production of false alarms. This is exemplified by application studies to a synthetic example from the literature and to the Tennessee Eastman benchmark process.},
	number = {8},
	urldate = {2016-10-14},
	journal = {J. Process Contr.},
	author = {Kruger, Uwe and Zhou, Yiqi and Irwin, George W},
	month = dec,
	year = {2004},
	keywords = {ARMA filters, Auto-correlated process variables, Multivariate Statistical Process Control},
	pages = {879--888},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\NS6GC3HQ\\Kruger et al. - 2004 - Improved principal component monitoring of large-s.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\ZU6RD4EG\\S0959152404000186.html:text/html}
}

@article{cheng_nonlinear_2005,
	title = {Nonlinear process monitoring using {JITL}-{PCA}},
	volume = {76},
	issn = {0169-7439},
	doi = {10.1016/j.chemolab.2004.08.003},
	abstract = {A new method is proposed for monitoring the nonlinear static or dynamic systems. In the proposed method, just-in-time learning (JITL) and principal component analysis (PCA) are integrated to construct JITL-PCA monitoring scheme, where JITL serves as the process model to account for the nonlinear and dynamic behavior of the process under normal operating conditions. The residuals resulting from the difference between JITL's predicted outputs and process outputs are analyzed by PCA to evaluate the status of the current process operating condition. Two nonlinear systems are used to illustrate the proposed method. Simulation results show that JITL-PCA outperforms both PCA and dynamic PCA in the monitoring of nonlinear static or dynamic systems.},
	number = {1},
	urldate = {2016-10-14},
	journal = {Chemometr. Intell. Lab.},
	author = {Cheng, Cheng and Chiu, Min-Sen},
	month = mar,
	year = {2005},
	keywords = {Just-in-time learning, Principal Component Analysis, Process monitoring},
	pages = {1--13},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\D5W8AM2T\\Cheng and Chiu - 2005 - Nonlinear process monitoring using JITL-PCA.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\Z4QNQZAD\\S0169743904001947.html:text/html}
}

@book{norman_markov_1972,
	edition = {1},
	title = {Markov {Process} and {Learning} {Models}},
	volume = {84},
	publisher = {New York: Academic Press},
	author = {Norman, M. Frank},
	year = {1972}
}

@article{kramer_nonlinear_1991,
	title = {Nonlinear principal component analysis using autoassociative neural networks},
	volume = {37},
	issn = {1547-5905},
	doi = {10.1002/aic.690370209},
	abstract = {Nonlinear principal component analysis is a novel technique for multivariate data analysis, similar to the well-known method of principal component analysis. NLPCA, like PCA, is used to identify and remove correlations among problem variables as an aid to dimensionality reduction, visualization, and exploratory data analysis. While PCA identifies only linear correlations between variables, NLPCA uncovers both linear and nonlinear correlations, without restriction on the character of the nonlinearities present in the data. NLPCA operates by training a feedforward neural network to perform the identity mapping, where the network inputs are reproduced at the output layer. The network contains an internal “bottleneck” layer (containing fewer nodes than input or output layers), which forces the network to develop a compact representation of the input data, and two additional hidden layers. The NLPCA method is demonstrated using time-dependent, simulated batch reaction data. Results show that NLPCA successfully reduces dimensionality and produces a feature space map resembling the actual distribution of the underlying system parameters.},
	language = {en},
	number = {2},
	urldate = {2016-10-14},
	journal = {AIChE J.},
	author = {Kramer, Mark A.},
	month = feb,
	year = {1991},
	pages = {233--243},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\WG8NS8SJ\\abstract.html:text/html}
}

@article{banadda_review_2011,
	title = {A review of modeling approaches in activated sludge systems},
	volume = {5},
	copyright = {Copyright is owned by Academic Journals},
	issn = {1996-0786},
	abstract = {The feasibility of using models to understand processes, predict and/or simulate, control, monitor and optimize WasteWater Treatment Plants (WWTPs) has been explored by a number of researchers. Mathematical modeling provides a powerful tool for design, operational assistance, forecast future behavior and control. A good model not only elucidates a better understanding of the complicated biological and chemical fundamentals but is also essential for process design, process start-up, dynamics predictions, process control and process optimization. This paper reviews developments and the application of different modeling approaches to wastewater treatment plants, especially activated sludge systems and processes therein in the last decade. In addition, we present an opinion on the wider wastewater treatment related research issues that need to be addressed through modeling.Key words: Mathematical modeling, water, wastewater, wastewater treatment plants, activated sludge systems.},
	language = {en},
	number = {6},
	urldate = {2016-10-14},
	journal = {Afr. J. Env. Sci. Tech.},
	author = {Banadda, N. and Nhapi, I. and Kimwaga, R.},
	month = jan,
	year = {2011},
	pages = {397--408},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\KXBQJITS\\Banadda et al. - 2011 - A review of modeling approaches in activated sludg.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\ZSM68G77\\71956.html:text/html}
}

@article{tubbs_linear_1982,
	title = {Linear dimension reduction and {Bayes} classification with unknown population parameters},
	volume = {15},
	abstract = {Odell and Decell, Odell and Coberly gave necessary and sufficient conditions for the smallest dimension compression matrix B such that the Bayes classification regions are preserved. That is, they developed an explicit expression of a compression matrix B such that the Bayes classification assignment are the same for both the original space x and the compressed space Bx. Odell indicated that whenever the population parameters are unknown, then the dimension of Bx is the same as x with probability one. Furthermore, Odell posed the problem of finding a lower dimension q {\textless} p which in some sense best fits the range space generated by the matrix M. The purpose of this paper is to discuss this problem and provide a partial solution. © 1982.},
	language = {English},
	number = {3},
	journal = {Pattern Recogn.},
	author = {Tubbs, J. D. and Coberly, W. A. and Young, D. M.},
	year = {1982},
	keywords = {Bayes classification procedure, Dimension reduction, Feature selection, Probability of misclassification, Projection operator, Singular value decomposition},
	pages = {167--172}
}

@article{cheng_adaptive_2010-1,
	title = {Adaptive kernel principal component analysis ({KPCA}) for monitoring small disturbances of nonlinear processes},
	volume = {49},
	issn = {0888-5885},
	doi = {10.1021/ie900521b},
	abstract = {The Tennessee Eastman (TE) process, created by Eastman Chemical Company, is a complex nonlinear process. Many previous studies focus on the detectability of monitoring a multivariate process by using TE process as an example. Principal component analysis (PCA) is a widely used dimension-reduction tool for monitoring multivariate linear process. Recently, the kernel principal component analysis (KPCA) has emerged as an effective method to tackling the problem of nonlinear data. Nevertheless, the conventional KPCA used the sum of squares of latest observations as the monitoring statistics and hence failed to detect small disturbance of the process. To enhance the detectability of the KPCA-based monitoring method, an adaptive KPCA-based monitoring statistic is proposed in this paper. The basic idea of the proposed method is first adopting the multivariate exponentially moving average to predict the process mean shifts and then combining the estimated mean shifts with the extracted components by KPCA to construct the adaptive monitoring statistic. The efficiency of the proposed monitoring scheme is implemented in a simulated nonlinear system and in the TE process. The experimental results indicate that the proposed method outperforms the traditional PCA and KPCA monitoring schemes.},
	number = {5},
	urldate = {2016-10-14},
	journal = {Ind. Eng. Chem. Res.},
	author = {Cheng, Chun-Yuan and Hsu, Chun-Chin and Chen, Mu-Chen},
	month = mar,
	year = {2010},
	pages = {2254--2262},
	file = {ACS Full Text PDF w/ Links:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\QT3NBNF4\\Cheng et al. - 2010 - Adaptive Kernel Principal Component Analysis (KPCA.pdf:application/pdf;ACS Full Text Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\DQIQH2H8\\ie900521b.html:text/html}
}

@article{cho_fault_2005,
	title = {Fault identification for process monitoring using kernel principal component analysis},
	volume = {60},
	issn = {0009-2509},
	doi = {10.1016/j.ces.2004.08.007},
	abstract = {In this research, we develop a new fault identification method for kernel principal component analysis (kernel PCA). Although it has been proved that kernel PCA is superior to linear PCA for fault detection, the fault identification method theoretically derived from the kernel PCA has not been found anywhere. Using the gradient of kernel function, we define two new statistics which represent the contribution of each variable to the monitoring statistics, Hotelling's T 2 and squared prediction error (SPE) of kernel PCA, respectively. The proposed statistics which have similar concept to contributions in linear PCA are directly derived from the mathematical formulation of kernel PCA and thus they are straightforward to understand. The main contribution of this work is that we firstly suggest a fault identification method especially applicable to process monitoring using kernel PCA. To demonstrate the performance, the proposed method is applied to two simulated processes, one is a simple nonlinear process and the other is a non-isothermal CSTR process. The simulation results show that the proposed method effectively identifies the source of various types of faults.},
	number = {1},
	urldate = {2016-10-14},
	journal = {Chem. Eng. Sci.},
	author = {Cho, Ji-Hoon and Lee, Jong-Min and Wook Choi, Sang and Lee, Dongkwon and Lee, In-Beum},
	month = jan,
	year = {2005},
	keywords = {Fault identification, Kernel principal component analysis, Nonlinear dynamics, Process monitoring, Safety, Systems engineering},
	pages = {279--288},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\A2TUNG9J\\Cho et al. - 2005 - Fault identification for process monitoring using .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\QISX7R84\\S0009250904006013.html:text/html}
}

@article{fan_quadro:_2015,
	title = {{QUADRO}: {A} supervised dimension reduction method via {Rayleigh} quotient optimization},
	volume = {43},
	issn = {0090-5364},
	shorttitle = {{QUADRO}},
	doi = {10.1214/14-AOS1307},
	abstract = {We propose a novel Rayleigh quotient based sparse quadratic dimension reduction method - named QUADRO (Quadratic Dimension Reduction via Rayleigh Optimization) - for analyzing high- dimensional data. Unlike in the linear setting where Rayleigh quotient optimization coincides with classification, these two problems are very different under nonlinear settings. In this paper, we clarify this difference and show that Rayleigh quotient optimization may be of independent scientific interests. One major challenge of Rayleigh quotient optimization is that the variance of quadratic statistics involves all fourth cross-moments of predictors, which are infeasible to compute for high-dimensional applications and may accumulate too many stochastic errors. This issue is resolved by considering a family of elliptical models. Moreover, for heavy-tail distributions, robust estimates of mean vectors and covariance matrices are employed to guarantee uniform convergence in estimating nonpolynomially many parameters, even though only the fourth moments are assumed. Methodologically, QUADRO is based on elliptical models which allow us to formulate the Rayleigh quotient maximization as a convex optimization problem. Computationally, we propose an efficient linearized augmented Lagrangian method to solve the constrained optimization problem. Theoretically, we provide explicit rates of convergence in terms of Rayleigh quotient under both Gaussian and general elliptical models. Thorough numerical results on both synthetic and real datasets are also provided to back up our theoretical results.},
	number = {4},
	urldate = {2016-09-15},
	journal = {Ann. Stat.},
	author = {Fan, Jianqing and Ke, Zheng Tracy and Liu, Han and Xia, Lucy},
	month = aug,
	year = {2015},
	keywords = {Statistics - Methodology},
	pages = {1498--1534},
	annote = {Comment: Published at http://dx.doi.org/10.1214/14-AOS1307 in the Annals of Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical Statistics (http://www.imstat.org)},
	file = {arXiv\:1311.5542 PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\S59SQN3T\\Fan et al. - 2015 - QUADRO A supervised dimension reduction method vi.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\7S4CR2FW\\1311.html:text/html}
}

@article{boulesteix_partial_2007,
	title = {Partial least squares: a versatile tool for the analysis of high-dimensional genomic data},
	volume = {8},
	issn = {1467-5463, 1477-4054},
	shorttitle = {Partial least squares},
	doi = {10.1093/bib/bbl016},
	language = {en},
	number = {1},
	urldate = {2016-06-22},
	journal = {Brief. Bioinform.},
	author = {Boulesteix, Anne-Laure and Strimmer, Korbinian},
	month = jan,
	year = {2007},
	pmid = {16772269},
	pages = {32--44},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\4M6AAUTQ\\Boulesteix and Strimmer - 2007 - Partial least squares a versatile tool for the an.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\HKIE7PQ2\\32.html:text/html}
}

@article{young_quadratic_1987,
	title = {Quadratic discrimination: {Some} results on optimal low-dimensional representation},
	volume = {17},
	issn = {0378-3758},
	shorttitle = {Quadratic discrimination},
	doi = {10.1016/0378-3758(87)90122-4},
	abstract = {A random vector is assumed to belong to one several multivariate normal distributions possibility having unequal covariance matrices. The goal is to find a low-dimensional hyperplane which preserves or nearly preserves the separation of the individual population. We present a computationally simple method of deriving a linear transformation for low-dimensional representation and give conditions under which the Bayes classification rule is preserved in the low-dimensional space. Finally, we give several examples to demonstrate the method.},
	urldate = {2016-06-23},
	journal = {J. Stat. Plan. Infer.},
	author = {Young, Dean M. and Marco, Virgil R. and Odell, Patrick L.},
	month = jan,
	year = {1987},
	keywords = {Bayes classification, Linear transformation, Probability of misclassification, Quadratic discrimination},
	pages = {307--319},
	file = {ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\TBFS7HV4\\0378375887901224.html:text/html}
}

@article{kazor_comparison_2016,
	title = {Comparison of linear and nonlinear dimension reduction techniques for automated process monitoring of a decentralized wastewater treatment facility},
	volume = {30},
	issn = {1436-3240, 1436-3259},
	doi = {10.1007/s00477-016-1246-2},
	abstract = {Multivariate statistical methods for online process monitoring have been widely applied to chemical, biological, and engineered systems. While methods based on principal component analysis (PCA) are popular, more recently kernel PCA (KPCA) and locally linear embedding (LLE) have been utilized to better model nonlinear process data. Additionally, various forms of dynamic and adaptive monitoring schemes have been proposed to address time-varying features in these processes. In this analysis, we extend a common simulation study in order to account for autocorrelation and nonstationarity in process data and comprehensively compare the monitoring performances of static, dynamic, adaptive, and adaptive–dynamic versions of PCA, KPCA, and LLE. Furthermore, we evaluate a nonparametric method to set thresholds for monitoring statistics and compare results with the standard parametric approaches. We then apply these methods to real-world data collected from a decentralized wastewater treatment system during normal and abnormal operations. From the simulation study, adaptive–dynamic versions of all three methods generally improve results when the process is autocorrelated and nonstationary. In the case study, adaptive–dynamic versions of PCA, KPCA, and LLE all flag a strong system fault, but nonparametric thresholds considerably reduce the number of false alarms for all three methods under normal operating conditions.},
	language = {en},
	number = {5},
	urldate = {2016-10-14},
	journal = {Stoch. Environ. Res. Risk Assess.},
	author = {Kazor, Karen and Holloway, Ryan W. and Cath, Tzahi Y. and Hering, Amanda S.},
	month = apr,
	year = {2016},
	pages = {1527--1544},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\FTB2ZU9R\\Kazor et al. - 2016 - Comparison of linear and nonlinear dimension reduc.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\6663W92D\\s00477-016-1246-2.html:text/html}
}

@book{stewart_introduction_1973,
	series = {Computer {Science} and {Applied} {Mathematics}},
	title = {Introduction to {Matrix} {Computations}},
	isbn = {0-12-670350-7},
	language = {en},
	publisher = {Academic Press},
	author = {Stewart, Gilbert W.},
	year = {1973}
}

@inproceedings{paschke_sensorlose_2013,
	title = {Sensorlose {Zustandsüberwachung} an {Synchronmotoren}},
	abstract = {Official Full-Text Publication: Sensorlose Zustandsüberwachung an Synchronmotoren on ResearchGate, the professional network for scientists.},
	urldate = {2017-01-17},
	booktitle = {{ResearchGate}},
	author = {Paschke, Fabian and Bayer, Christian and Bator, Martyna and Monks, Uwe and Dicks, Alexander and Enge-Rosenblatt, Olaf and Lohweg, Volker},
	month = dec,
	year = {2013},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\V6SW78M8\\Paschke et al. - 2013 - Sensorlose Zustandsüberwachung an Synchronmotoren.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\FGZ2Q47R\\262698433_Sensorlose_Zustandsuberwachung_an_Synchronmotoren.html:text/html}
}

@inproceedings{chouaib_adaptive_2013,
	title = {Adaptive kernel principal component analysis for nonlinear dynamic process monitoring},
	doi = {10.1109/ASCC.2013.6606291},
	abstract = {In this paper a new algorithms for adaptive kernel principal component analysis (AKPCA) is proposed for dynamic process monitoring. The proposed AKPCA algorithm combine two existing algorithm, the recursive weighted PCA (RWPCA) and the moving window kernel PCA algorithms. For fault detection and isolation, a set of structured residuals is generated by using a partial AKPCA models. Each partial AKPCA model is performed on subsets of variables. The structured residuals are utilized in composing an isolation scheme, according to a properly designed incidence matrix. The results for applying this algorithm on the nonlinear time varying processes of the Tennessee Eastman shows its feasibility and advantageous performances.},
	booktitle = {Control {Conference} ({ASCC}), 2013 9th {Asian}},
	author = {Chouaib, C. and Mohamed-Faouzi, H. and Messaoud, D.},
	month = jun,
	year = {2013},
	keywords = {Adaptation models, adaptive kernel principal component analysis, AKPCA algorithm, chemical engineering, control charts, Covariance matrices, Fault detection, fault diagnosis, fault isolation, fault tolerance, incidence matrix design, isolation scheme, Kernel, Mathematical model, Monitoring, moving window kernel PCA algorithm, nonlinear dynamical systems, nonlinear dynamic process monitoring, nonlinear time varying process, partial AKPCA models, Principal Component Analysis, Process monitoring, production engineering computing, recursive weighted PCA algorithm, structured residuals, Tennessee Eastman process, Vectors},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\RW9RW6H7\\6606291.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\SNAFMBK8\\Chouaib et al. - 2013 - Adaptive kernel principal component analysis for n.pdf:application/pdf}
}

@article{barker_partial_2003,
	title = {Partial least squares for discrimination},
	volume = {17},
	number = {3},
	urldate = {2016-06-22},
	journal = {J. Chemometr.},
	author = {Barker, Matthew and Rayens, William},
	year = {2003},
	pages = {166--173},
	file = {[PDF] from researchgate.net:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\XD387UQN\\Barker and Rayens - 2003 - Partial least squares for discrimination.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\37SS86KN\\abstract\;jsessionid=B9F5094ED4C4AE249759F7B76E10E15B.html:text/html}
}

@article{lee_nonlinear_2004,
	title = {Nonlinear process monitoring using kernel principal component analysis},
	volume = {59},
	issn = {0009-2509},
	doi = {10.1016/j.ces.2003.09.012},
	abstract = {In this paper, a new nonlinear process monitoring technique based on kernel principal component analysis (KPCA) is developed. KPCA has emerged in recent years as a promising method for tackling nonlinear systems. KPCA can efficiently compute principal components in high-dimensional feature spaces by means of integral operators and nonlinear kernel functions. The basic idea of KPCA is to first map the input space into a feature space via nonlinear mapping and then to compute the principal components in that feature space. In comparison to other nonlinear principal component analysis (PCA) techniques, KPCA requires only the solution of an eigenvalue problem and does not entail any nonlinear optimization. In addition, the number of principal components need not be specified prior to modeling. In this paper, a simple approach to calculating the squared prediction error (SPE) in the feature space is also suggested. Based on T2 and SPE charts in the feature space, KPCA was applied to fault detection in two example systems: a simple multivariate process and the simulation benchmark of the biological wastewater treatment process. The proposed approach effectively captured the nonlinear relationship in the process variables and showed superior process monitoring performance compared to linear PCA.},
	number = {1},
	urldate = {2016-10-14},
	journal = {Chem. Eng. Sci.},
	author = {Lee, Jong-Min and Yoo, ChangKyoo and Choi, Sang Wook and Vanrolleghem, Peter A. and Lee, In-Beum},
	month = jan,
	year = {2004},
	keywords = {Fault detection, Kernel principal component analysis, Nonlinear dynamics, Process control, Safety, Systems engineering},
	pages = {223--234},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\H7Z4989G\\Lee et al. - 2004 - Nonlinear process monitoring using kernel principa.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\P3IPA8RE\\S0009250903004652.html:text/html}
}

@article{belkin_laplacian_2003,
	title = {Laplacian eigenmaps for dimensionality reduction and data representation},
	volume = {15},
	issn = {0899-7667},
	doi = {10.1162/089976603321780317},
	abstract = {One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed.},
	number = {6},
	urldate = {2016-10-14},
	journal = {Neural Comput.},
	author = {Belkin, Mikhail and Niyogi, Partha},
	month = jun,
	year = {2003},
	pages = {1373--1396}
}

@article{woodall_current_2014,
	title = {Some current directions in the theory and application of statistical process monitoring},
	volume = {46},
	copyright = {Copyright American Society for Quality Jan 2014},
	issn = {00224065},
	abstract = {The purpose of this paper is to provide an overview and our perspective of recent research and applications of statistical process monitoring. The focus is on work done over the past decade or so. We review briefly a number of important areas, including health-related monitoring, spatiotemporal surveillance, profile monitoring, use of autocorrelated data, the effect of estimation error, and high-dimensional monitoring, among others. We briefly discuss the choice of performance metrics. We provide references and offer some directions for further research. [PUBLICATION ABSTRACT]},
	language = {English},
	number = {1},
	urldate = {2016-10-17},
	journal = {J. Qual. Technol.},
	author = {Woodall, William H. and Montgomery, Douglas C.},
	month = jan,
	year = {2014},
	keywords = {control charts, Engineering--Engineering Mechanics And Materials, Health care, Public health, Statistical process control, Studies, Surveillance},
	pages = {78--94},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\N54ZC8IU\\Woodall and Montgomery - 2014 - Some Current Directions in the Theory and Applicat.pdf:application/pdf}
}

@book{bellman_adaptive_1961,
	title = {Adaptive {Control} {Processes}: {A} {Guided} {Tour}},
	isbn = {978-0-691-07901-1},
	shorttitle = {Adaptive {Control} {Processes}},
	abstract = {The book description for "Adaptive Control Processes" is currently unavailable.},
	urldate = {2016-06-22},
	publisher = {Princeton University Press},
	author = {Bellman, Richard},
	year = {1961},
	annote = {Curse of Dimensionality: Chapter 5.16, page 94.}
}

@article{maulud_multi-scale_2006,
	title = {A multi-scale orthogonal nonlinear strategy for multi-variate statistical process monitoring},
	volume = {16},
	issn = {0959-1524},
	doi = {10.1016/j.jprocont.2006.01.006},
	abstract = {In this paper a multi-scale nonlinear PCA strategy for process monitoring is proposed. The strategy utilizes the optimal wavelet decomposition in such a way that only the approximation and the highest detail functions are used, thus simplifying the overall structure and making the interpretation at each scale more meaningful. An orthogonal nonlinear PCA procedure is incorporated to capture the nonlinear characteristics with a minimum number of principal components. The proposed nonlinear strategy also eliminates the requirement of nonlinear functions relating the nonlinear principal scores to process measurements for Q-statistics as in other nonlinear PCA process monitoring approaches. In addition, the strategy is considerably robust to the presence of typical outliers.},
	number = {7},
	urldate = {2016-10-14},
	journal = {J. Process Contr.},
	author = {Maulud, A. and Wang, D. and Romagnoli, J. A.},
	month = aug,
	year = {2006},
	keywords = {Fault detection, Optimal wavelet decomposition, Orthogonal nonlinear PCA, Robust},
	pages = {671--683},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\H9EUX687\\Maulud et al. - 2006 - A multi-scale orthogonal nonlinear strategy for mu.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\QEJRTJGN\\S0959152406000199.html:text/html}
}

@article{peck_comparison_1988,
	title = {A comparison of several biased estimators for improving the expected error rate of the sample quadratic discriminant function},
	volume = {29},
	issn = {0094-9655},
	doi = {10.1080/00949658808811057},
	abstract = {The sample quadratic discriminant function (QDF) has been shown by Marks and Dunn (1974) to be superior to the linear discriminant function for two normal populations with , provided the training sample sizesn 1and n 2, are sufficiently large. However, the performance of the QDF quickly deteriorates as the dimension p increases relative to the sample size n i i = l , 2 . The deterioration is principally due to poor estimates of the inverse of the covariance matrices, . One method of combating this problem is to apply biased estimators of the inverse of the covariance matrices. In this paper we contrast the performance of the QDF with respect to several biased estimators and one unbiased estimator of A shrinkage estimator proposed by Peck and Van Ness (1982) is found to yield superior performance over a wide range of configurations and training sample sizes.},
	number = {2},
	urldate = {2016-09-15},
	journal = {J. Stat. Comput. Sim.},
	author = {Peck, Roger and Jennings, Linda W. and Young, Dean M.},
	month = apr,
	year = {1988},
	pages = {143--156},
	file = {Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\KZ849C6Z\\00949658808811057.html:text/html}
}

@misc{noauthor_notitle_nodate,
	url = {https://scholar.googleusercontent.com/scholar.bib?q=info:9IPZtHliT8IJ:scholar.google.com/&output=citation&scisig=AAGBfm0AAAAAWAFgLrm9ymst9of9ejMvSZnsLdSstmd9&scisf=4&ct=citation&cd=-1&hl=en},
	urldate = {2016-10-14},
	file = {:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\6QM6UBV9\\scholar.txt:text/plain}
}

@article{mina_fault_2007,
	title = {Fault detection for large scale systems using dynamic principal components analysis with adaptation},
	volume = {2},
	copyright = {Copyright (c) 2016 International Journal of Computers Communications \& Control},
	issn = {1841-9836},
	doi = {10.15837/ijccc.2007.2.2351},
	abstract = {The Dynamic Principal Component Analysis is an adequate tool for the monitoring of large scale systems based on the model of multivariate historical data under the assumption of stationarity, however, false alarms occur for non-stationary new observations during the monitoring phase. In order to reduce the false alarms rate, this paper extends the DPCA based monitoring for non-stationary data of linear dynamic systems, including an on-line means estimator to standardize new observations according to the estimated means. The effectiveness of the proposed methodology is evaluated for fault detection in a interconnected tanks system.},
	language = {en},
	number = {2},
	urldate = {2016-10-14},
	journal = {Int. J. Comput. Commun.},
	author = {Mina, Jesus and Verde, Cristina},
	month = apr,
	year = {2007},
	keywords = {Dynamic Principal Component Analysis, Fault detection, Non-Stationary Signals, statistical analysis, Time Series Analysis},
	pages = {185--194},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\42K3W39C\\Mina and Verde - 2007 - Fault Detection for Large Scale Systems Using Dyna.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\ZNT97BPA\\2351.html:text/html}
}

@book{hastie_elements_2001,
	address = {New York},
	series = {Springer series in statistics},
	title = {The elements of statistical learning: data mining, inference, and prediction: with 200 full-color illustrations},
	isbn = {978-0-387-95284-0},
	shorttitle = {The elements of statistical learning},
	publisher = {Springer},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, J. H.},
	year = {2001},
	keywords = {Supervised learning (Machine learning)}
}

@article{alon_broad_1999,
	title = {Broad patterns of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonucleotide arrays},
	volume = {96},
	issn = {0027-8424},
	abstract = {Oligonucleotide arrays can provide a broad picture of the state of the cell, by monitoring the expression level of thousands of genes at the same time. It is of interest to develop techniques for extracting useful information from the resulting data sets. Here we report the application of a two-way clustering method for analyzing a data set consisting of the expression patterns of different cell types. Gene expression in 40 tumor and 22 normal colon tissue samples was analyzed with an Affymetrix oligonucleotide array complementary to more than 6,500 human genes. An efficient two-way clustering algorithm was applied to both the genes and the tissues, revealing broad coherent patterns that suggest a high degree of organization underlying gene expression in these tissues. Coregulated families of genes clustered together, as demonstrated for the ribosomal proteins. Clustering also separated cancerous from noncancerous tissue and cell lines from in vivo tissues on the basis of subtle distributed patterns of genes even when expression of individual genes varied only slightly between the tissues. Two-way clustering thus may be of use both in classifying genes into functional groups and in classifying tissues based on gene expression.},
	language = {eng},
	number = {12},
	journal = {Proc. Natl. Acad. Sci. U.S.A.},
	author = {Alon, U. and Barkai, N. and Notterman, D. A. and Gish, K. and Ybarra, S. and Mack, D. and Levine, A. J.},
	month = jun,
	year = {1999},
	pmid = {10359783},
	pmcid = {PMC21986},
	keywords = {Adenocarcinoma, Cluster Analysis, Colonic Neoplasms, Gene Expression Regulation, Neoplastic, Humans, Oligonucleotide Probes},
	pages = {6745--6750}
}

@article{li_sparse_2015,
	title = {Sparse quadratic discriminant analysis for high dimensional data},
	volume = {25},
	issn = {1017-0405},
	abstract = {Many contemporary studies involve the classification of a subject into two classes based on n observations of the p variables associated with the subject. Under the assumption that the variables are normally distributed, the well-known linear discriminant analysis (LDA) assumes a common covariance matrix over the two classes while the quadratic discriminant analysis (QDA) allows different covariance matrices. When p is much smaller than n, even if they both diverge, the LDA and QDA have the smallest asymptotic misclassification rates for the cases of equal and unequal covariance matrices, respectively. However, modern statistical studies often face classification problems with the number of variables much larger than the sample size n, and the classical LDA and QDA can perform poorly. In fact, we give an example in which the QDA performs as poorly as random guessing even if we know the true covariances. Under some sparsity conditions on the unknown means and covariance matrices of the two classes, we propose a sparse QDA based on thresholding that has the smallest asymptotic misclassification rate conditional on the training data. We discuss an example of classifying normal and tumor colon tissues based on a set of p = 2,000 genes and a sample of size n = 62, and another example of a cardiovascular study for n = 222 subjects with p = 2,434 genes. A simulation is also conducted to check the performance of the proposed method.},
	number = {2},
	urldate = {2017-03-28},
	journal = {Statistica Sinica},
	author = {Li, Quefeng and Shao, Jun},
	year = {2015},
	pages = {457--473}
}

@article{dettling_bagboosting_2004,
	title = {{BagBoosting} for tumor classification with gene expression data},
	volume = {20},
	issn = {1367-4803, 1460-2059},
	doi = {10.1093/bioinformatics/bth447},
	language = {en},
	number = {18},
	urldate = {2017-03-28},
	journal = {Bioinformatics},
	author = {Dettling, M.},
	month = dec,
	year = {2004},
	pages = {3583--3593}
}

@article{weinberger_unsupervised_2006,
	title = {Unsupervised {Learning} of {Image} {Manifolds} by {Semidefinite} {Programming}},
	volume = {70},
	issn = {0920-5691, 1573-1405},
	url = {https://link.springer.com/article/10.1007/s11263-005-4939-z},
	doi = {10.1007/s11263-005-4939-z},
	abstract = {Can we detect low dimensional structure in high dimensional data sets of images? In this paper, we propose an algorithm for unsupervised learning of image manifolds by semidefinite programming. Given a data set of images, our algorithm computes a low dimensional representation of each image with the property that distances between nearby images are preserved. More generally, it can be used to analyze high dimensional data that lies on or near a low dimensional manifold. We illustrate the algorithm on easily visualized examples of curves and surfaces, as well as on actual images of faces, handwritten digits, and solid objects.},
	language = {en},
	number = {1},
	urldate = {2017-03-28},
	journal = {Int J Comput Vision},
	author = {Weinberger, Kilian Q. and Saul, Lawrence K.},
	month = oct,
	year = {2006},
	pages = {77--90},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\KR9FM3TA\\Weinberger and Saul - 2006 - Unsupervised Learning of Image Manifolds by Semide.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\VUXBU9KP\\10.html:text/html}
}

@article{tenenbaum_global_2000-1,
	title = {A {Global} {Geometric} {Framework} for {Nonlinear} {Dimensionality} {Reduction}},
	volume = {290},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.290.5500.2319},
	abstract = {Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs—30,000 auditory nerve fibers or 106 optic nerve fibers—a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.},
	language = {en},
	number = {5500},
	urldate = {2017-03-28},
	journal = {Science},
	author = {Tenenbaum, Joshua B. and Silva, Vin de and Langford, John C.},
	month = dec,
	year = {2000},
	pmid = {11125149},
	pages = {2319--2323},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\WU3JBC8F\\Tenenbaum et al. - 2000 - A Global Geometric Framework for Nonlinear Dimensi.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\6FD87SCH\\2319.html:text/html}
}

@article{breiman_random_2001,
	title = {Random {Forests}},
	volume = {45},
	issn = {0885-6125, 1573-0565},
	doi = {10.1023/A:1010933404324},
	abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
	language = {en},
	number = {1},
	urldate = {2017-03-30},
	journal = {Machine Learning},
	author = {Breiman, Leo},
	month = oct,
	year = {2001},
	pages = {5--32},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\TF4GNKSR\\Breiman - 2001 - Random Forests.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\G55URQSK\\A1010933404324.html:text/html}
}

@book{cunningham_k-nearest_2007,
	title = {k-{Nearest} {Neighbour} {Classifiers}},
	abstract = {Abstract. Perhaps the most straightforward classifier in the arsenal or machine learning techniques is the Nearest Neighbour Classifier – classification is achieved by identifying the nearest neighbours to a query example and using those neighbours to determine the class of the query. This approach to classification is of particular importance today because issues of poor run-time performance is not such a problem these days with the computational power that is available. This paper presents an overview of techniques for Nearest Neighbour classification focusing on; mechanisms for assessing similarity (distance), computational issues in identifying nearest neighbours and mechanisms for reducing the dimension of the data. 1},
	author = {Cunningham, Pádraig and Delany, Sarah Jane},
	year = {2007},
	file = {Citeseer - Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\4ZN6PXIZ\\Cunningham and Delany - 2007 - k-Nearest Neighbour Classifiers.pdf:application/pdf;Citeseer - Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\SRBJMIK3\\summary.html:text/html}
}

@article{pang_shrinkage-based_2009,
	title = {Shrinkage-based {Diagonal} {Discriminant} {Analysis} and {Its} {Applications} in {High}-dimensional {Data}},
	volume = {65},
	issn = {0006-341X},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2794982/},
	doi = {10.1111/j.1541-0420.2009.01200.x},
	abstract = {High dimensional data such as microarrays has brought us new statistical challenges. For example, using a large number of genes to classify samples based on a small number of microarrays remains a difficult problem. Diagonal Discriminant Analysis, Support Vector Machines and k-Nearest Neighbor have been suggested as among the best methods for small sample size situations, but none was found to be superior to others. In this article, we propose an improved diagonal discriminant approach through shrinkage and regularization of the variances. The performance of our new approach along with the existing methods is studied through simulations and applications to real data. These studies show that the proposed shrinkage-based and regularization diagonal discriminant methods have lower misclassification rates than existing methods in many cases.},
	number = {4},
	urldate = {2017-03-30},
	journal = {Biometrics},
	author = {Pang, Herbert and Tong, Tiejun and Zhao, Hongyu},
	month = dec,
	year = {2009},
	pmid = {19302409},
	pmcid = {PMC2794982},
	pages = {1021--1029},
	file = {PubMed Central Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\87WHCGNP\\Pang et al. - 2009 - Shrinkage-based Diagonal Discriminant Analysis and.pdf:application/pdf}
}

@article{schapire_strength_1990,
	title = {The strength of weak learnability},
	volume = {5},
	issn = {0885-6125, 1573-0565},
	url = {https://link.springer.com/article/10.1007/BF00116037},
	doi = {10.1007/BF00116037},
	abstract = {This paper addresses the problem of improving the accuracy of an hypothesis output by a learning algorithm in the distribution-free (PAC) learning model. A concept class islearnable (orstrongly learnable) if, given access to a source of examples of the unknown concept, the learner with high probability is able to output an hypothesis that is correct on all but an arbitrarily small fraction of the instances. The concept class isweakly learnable if the learner can produce an hypothesis that performs only slightly better than random guessing. In this paper, it is shown that these two notions of learnability are equivalent.A method is described for converting a weak learning algorithm into one that achieves arbitrarily high accuracy. This construction may have practical applications as a tool for efficiently converting a mediocre learning algorithm into one that performs extremely well. In addition, the construction has some interesting theoretical consequences, including a set of general upper bounds on the complexity of any strong learning algorithm as a function of the allowed error ο.},
	language = {en},
	number = {2},
	urldate = {2017-03-30},
	journal = {Mach Learn},
	author = {Schapire, Robert E.},
	month = jun,
	year = {1990},
	pages = {197--227},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\3XZ3DJBA\\Schapire - 1990 - The strength of weak learnability.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\JTZ9GBN3\\BF00116037.html:text/html}
}

@article{choi_nearest_2017,
	title = {Nearest shrunken centroids via alternative genewise shrinkages},
	volume = {12},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0171068},
	abstract = {Nearest shrunken centroids (NSC) is a popular classification method for microarray data. NSC calculates centroids for each class and “shrinks” the centroids toward 0 using soft thresholding. Future observations are then assigned to the class with the minimum distance between the observation and the (shrunken) centroid. Under certain conditions the soft shrinkage used by NSC is equivalent to a LASSO penalty. However, this penalty can produce biased estimates when the true coefficients are large. In addition, NSC ignores the fact that multiple measures of the same gene are likely to be related to one another. We consider several alternative genewise shrinkage methods to address the aforementioned shortcomings of NSC. Three alternative penalties were considered: the smoothly clipped absolute deviation (SCAD), the adaptive LASSO (ADA), and the minimax concave penalty (MCP). We also showed that NSC can be performed in a genewise manner. Classification methods were derived for each alternative shrinkage method or alternative genewise penalty, and the performance of each new classification method was compared with that of conventional NSC on several simulated and real microarray data sets. Moreover, we applied the geometric mean approach for the alternative penalty functions. In general the alternative (genewise) penalties required fewer genes than NSC. The geometric mean of the class-specific prediction accuracies was improved, as well as the overall predictive accuracy in some cases. These results indicate that these alternative penalties should be considered when using NSC.},
	number = {2},
	urldate = {2017-03-30},
	journal = {PLOS ONE},
	author = {Choi, Byeong Yeob and Bair, Eric and Lee, Jae Won},
	month = feb,
	year = {2017},
	keywords = {Acute lymphoblastic leukemia, Adenocarcinomas, Central nervous system, Gene expression, Gene prediction, Linear discriminant analysis, Microarrays, Simulation and modeling},
	pages = {e0171068},
	file = {Full Text PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\AM7P4MZZ\\Choi et al. - 2017 - Nearest shrunken centroids via alternative genewis.pdf:application/pdf;Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\FPSQQXXD\\article.html:text/html}
}

@article{ramey_high-dimensional_2016,
	title = {High-{Dimensional} {Regularized} {Discriminant} {Analysis}},
	abstract = {Regularized discriminant analysis (RDA), proposed by Friedman (1989), is a widely popular classifier that lacks interpretability and is impractical for high-dimensional data sets. Here, we present an interpretable and computationally efficient classifier called high-dimensional RDA (HDRDA), designed for the small-sample, high-dimensional setting. For HDRDA, we show that each training observation, regardless of class, contributes to the class covariance matrix, resulting in an interpretable estimator that borrows from the pooled sample covariance matrix. Moreover, we show that HDRDA is equivalent to a classifier in a reduced-feature space with dimension approximately equal to the training sample size. As a result, the matrix operations employed by HDRDA are computationally linear in the number of features, making the classifier well-suited for high-dimensional classification in practice. We demonstrate that HDRDA is often superior to several sparse and regularized classifiers in terms of classification accuracy with three artificial and six real high-dimensional data sets. Also, timing comparisons between our HDRDA implementation in the sparsediscrim R package and the standard RDA formulation in the klaR R package demonstrate that as the number of features increases, the computational runtime of HDRDA is drastically smaller than that of RDA.},
	urldate = {2017-03-30},
	journal = {arXiv:1602.01182 [stat]},
	author = {Ramey, John A. and Stein, Caleb K. and Young, Phil D. and Young, Dean M.},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.01182},
	keywords = {62H30, 65F15, 65F20, 65F22, Statistics - Machine Learning},
	file = {arXiv\:1602.01182 PDF:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\Q5AXSQK8\\Ramey et al. - 2016 - High-Dimensional Regularized Discriminant Analysis.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\gabriel_odom\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\vpk8pptb.default-1490567675030\\zotero\\storage\\7758BPCC\\1602.html:text/html}
}

@article{guo_regularized_2007,
	title = {Regularized linear discriminant analysis and its application in microarrays},
	volume = {8},
	issn = {1465-4644, 1468-4357},
	doi = {10.1093/biostatistics/kxj035},
	language = {en},
	number = {1},
	urldate = {2017-03-30},
	journal = {Biostatistics},
	author = {Guo, Y. and Hastie, T. and Tibshirani, R.},
	month = jan,
	year = {2007},
	pages = {86--100}
}